{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "### Note for the homework: You can add further images or comments in the submitted PDF file if you don't want to do it here.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# path to store the data\n",
        "%cd /content/drive/My Drive/dl4nlp_2023/"
      ],
      "metadata": {
        "id": "nGB4JqofLLmq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fae7b372-f51e-4991-ff33-65d696baa64e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/dl4nlp_2023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell to intall/import all denpendicies needed for this homework; you can also add arbitrary libararies.\n",
        "\n",
        "!pip install datasets\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from nltk import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from scipy.stats import pearsonr, kendalltau\n",
        "from pprint import pprint \n",
        "import matplotlib.pyplot as plt\n",
        "import gdown"
      ],
      "metadata": {
        "id": "miNDnOd0LbBY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16cd0f58-3b8d-46c9-a456-1977eb860587"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.14.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This function is used to specify the random seeds that could impact pytorch.\n",
        "\n",
        "def seed_everything(seed: int):\n",
        "    import random, os\n",
        "    import numpy as np\n",
        "    import torch\n",
        "\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.set_default_tensor_type(torch.DoubleTensor) #added to avoid datatype problems"
      ],
      "metadata": {
        "id": "Es9RfIGNCQZt"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 1: Getting to Know Pytorch: Semantic Textual Similarity**\n",
        "\n",
        "In this task, we define semantic textual similarity (STS) as a **supervised** regression task in which the semantic similarity of two pieces of text (typically sentences) should be determined. "
      ],
      "metadata": {
        "id": "MdbEnTaRxKuJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 1.1: Data Preparation**\n",
        "\n",
        "**Run the following cell to load the dataset for this task first**. Each entry of this dataset contains one English sentence pair and their similarity score. \n",
        "\n",
        "To get familiar with the data format, please **print** the first entry of `train_set`, the size of `dev_set`, and the first 3 `sentence1` in `train_set`.\n",
        "\n",
        "**Hint**: the data is structured like both Python dictionary and Pandas DataFrame.\n",
        "\n"
      ],
      "metadata": {
        "id": "teX4DZdmMw_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = load_dataset(\"stsb_multi_mt\", \"en\", split='train')\n",
        "dev_set = load_dataset(\"stsb_multi_mt\", \"en\", split='dev')\n",
        "\n",
        "dev_set"
      ],
      "metadata": {
        "id": "IrMWHPUlzhD9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9adc771f-7a75-427c-aa51-105c76b15f68"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset stsb_multi_mt (/root/.cache/huggingface/datasets/stsb_multi_mt/en/1.0.0/a5d260e4b7aa82d1ab7379523a005a366d9b124c76a5a5cf0c4c5365458b0ba9)\n",
            "WARNING:datasets.builder:Found cached dataset stsb_multi_mt (/root/.cache/huggingface/datasets/stsb_multi_mt/en/1.0.0/a5d260e4b7aa82d1ab7379523a005a366d9b124c76a5a5cf0c4c5365458b0ba9)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['sentence1', 'sentence2', 'similarity_score'],\n",
              "    num_rows: 1500\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Useful documentation of the dataset\n",
        "\n",
        "https://huggingface.co/datasets/stsb_multi_mt"
      ],
      "metadata": {
        "id": "ChseQ5hpCzEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: YOUR CODE HERE\n",
        "print(f\"First Entry:  {train_set[0]}\")\n",
        "print(f\"Size of dev set: {len(dev_set)}\")\n",
        "print('First 3 sentence1 in train_set:', train_set[\"sentence1\"][:3])"
      ],
      "metadata": {
        "id": "fsb2SOHOyXqi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aaad6d1-2a87-42ae-85d3-57f7857488d4"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Entry:  {'sentence1': 'A plane is taking off.', 'sentence2': 'An air plane is taking off.', 'similarity_score': 5.0}\n",
            "Size of dev set: 1500\n",
            "First 3 sentence1 in train_set: ['A plane is taking off.', 'A man is playing a large flute.', 'A man is spreading shreded cheese on a pizza.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Task 1.1.1: Embed the sentences**\n",
        "We will use the averages of the words' [FastText embeddings](https://fasttext.cc/docs/en/english-vectors.html) to embed both sentences. \n",
        "\n",
        "**Run the following cell to download the embeddings.**"
      ],
      "metadata": {
        "id": "krKdguNXXWTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download word emebddings to your drive and unzip the file (run this cell only when you haven't downloaded the emb file yet.)\n",
        "\"\"\"!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
        "!unzip wiki-news-300d-1M.vec.zip\"\"\""
      ],
      "metadata": {
        "id": "NQUHJaFPVI7T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d93c718a-d014-4ef5-bdfd-d617b3354591"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\\n!unzip wiki-news-300d-1M.vec.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a) \n",
        "Implement a funtion to read the word embeddings into a Python dictionary that maps every token to the corresponding vector. Represent the vectors as Numpy arrays. Only load the embeddings of the first 40,000 tokens in the file. \n",
        "\n",
        "**Print** the size of the dictionary and the first 20 dimensions of the embedding for word \"homework\"."
      ],
      "metadata": {
        "id": "S7DXiaUCX1Ob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gensim\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "def load_embeddings(file=\"wiki-news-300d-1M.vec\", limit=40000):\n",
        "  # TODO: YOUR CODE HERE\n",
        "  embeddings = KeyedVectors.load_word2vec_format(\"/content/drive/MyDrive/dl4nlp_2023/wiki-news-300d-1M.vec\", binary=False, limit=limit)\n",
        "\n",
        "  out = {}\n",
        "  all_words = embeddings.index_to_key\n",
        "  for w in all_words:\n",
        "    out[w] = embeddings[w]\n",
        "\n",
        "  return out\n",
        "\n",
        "word_embedding_dict = load_embeddings() \n"
      ],
      "metadata": {
        "id": "j8iYJsKWXRvF"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"First 20 dimensions of homework: \\n\", word_embedding_dict[\"homework\"][:20])\n",
        "print(\"\\n\")\n",
        "print(\"Size of dictionary: \", len(word_embedding_dict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSSESAuNKNql",
        "outputId": "8c9c0d9b-cfe3-43df-ffb6-64eeb5886cf5"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 20 dimensions of homework: \n",
            " [-0.1756  0.0695  0.0847  0.0988 -0.1196 -0.1389 -0.0379  0.0543  0.1022\n",
            " -0.0082 -0.0488 -0.1748 -0.0181 -0.131  -0.1794  0.2143 -0.1612 -0.113\n",
            "  0.0213 -0.0763]\n",
            "\n",
            "\n",
            "Size of dictionary:  40000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SHAPE_EMBEDDING = word_embedding_dict[\"homework\"].shape\n",
        "ss = word_embedding_dict[\"homework\"].shape\n",
        "len(np.zeros(ss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78iPvchqPwC1",
        "outputId": "229b8a52-b2b1-4203-982b-b84731df5dd8"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b)\n",
        "Implement a function that tokenizes a sentence using [nltk.word_tokenize](https://www.nltk.org/book/ch03.html#accessing-text-from-the-web-and-from-disk) and returns a list of tokens for given sentence.\n",
        "\n",
        "**Print** the tokenized sentence1 and sentence2 of the first entry in the training set. "
      ],
      "metadata": {
        "id": "T2AbFPoZZ085"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(sentence):\n",
        "  # TODO: YOUR CODE HERE\n",
        "  return nltk.word_tokenize(sentence)\n",
        "\n",
        "s1 = train_set[0][\"sentence1\"]\n",
        "s2 = train_set[0][\"sentence2\"]\n",
        "\n",
        "s1_tokenized = tokenize(s1)\n",
        "s2_tokenized = tokenize(s2)\n",
        "\n",
        "print(f\"sentence1 : {s1_tokenized}\")\n",
        "print(f\"sentence2 : {s2_tokenized}\")"
      ],
      "metadata": {
        "id": "TDW3rQcpZzTd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33c3a75a-ace2-4b74-dcad-30bb85728c75"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentence1 : ['A', 'plane', 'is', 'taking', 'off', '.']\n",
            "sentence2 : ['An', 'air', 'plane', 'is', 'taking', 'off', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### c)\n",
        "Implement a function that maps a sentence to its embedding. The sentence-level embedding should be the average of the embeddings of its tokens. If a token does not exist in the vocabulary of FastText, embed this token as a 0-vector with the same dimensions as the FastText embeddings.\n",
        "\n",
        "**Print** the shape and the first 20 dimensions of sentence1's embedding of the first entry in the training set.\n"
      ],
      "metadata": {
        "id": "PFQk7vFSd6zh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_sentence(sentence, word2emb):\n",
        "  # TODO: YOUR CODE HERE\n",
        "  sum_embeddings = np.zeros(SHAPE_EMBEDDING)\n",
        "  tokenized_sentence = tokenize(sentence)\n",
        "  nb_word_in_sentence = len(tokenized_sentence) \n",
        "  all_words_dict = word2emb.keys() #get all words in the dict\n",
        "  for word in tokenized_sentence:\n",
        "    #check whether the word has an embedding\n",
        "    if word in all_words_dict:\n",
        "      emb = np.array(word2emb[word])\n",
        "      sum_embeddings += emb\n",
        "    #else block unecessary since adding zero numpy array does not change the outcome\n",
        "  # average the embeddings\n",
        "  return sum_embeddings / nb_word_in_sentence"
      ],
      "metadata": {
        "id": "j-P-y9DIdrOf"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent1_emb = embed_sentence(train_set[0][\"sentence1\"], word_embedding_dict) #get the embedding of the first sentence of the training set\n",
        "print(f\"Shape : {sent1_emb.shape}\\n\")\n",
        "print(f\"First 20 dimensions : \\n{sent1_emb[:20]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBc-0LjdQ2Lo",
        "outputId": "fca4fd37-7f25-444a-9b3b-ebb2bfca540f"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape : (300,)\n",
            "\n",
            "First 20 dimensions : \n",
            "[ 0.01895     0.01555    -0.03663333  0.04301667 -0.05261667 -0.043\n",
            " -0.05235    -0.02503333 -0.01348333 -0.02275     0.023      -0.00196667\n",
            "  0.01398333 -0.01931667  0.04275     0.02686667 -0.00416667  0.05871667\n",
            " -0.06091667  0.0174    ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Task 1.1.2: Build Custom Dataset**\n"
      ],
      "metadata": {
        "id": "jvCG_1zHoImu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a)\n",
        "Implement a custom dataset class inheriting [torch.utils.data.Dataset](https://pytorch.org/docs/stable/data.html#data-loading-order-and-sampler) and override the following methods:\n",
        "- `__len__`: which returns the size of the dataset.\n",
        "- `__getitem__`: to support the indexing such that dataset[i] can be used to get `ith` sample. \n",
        "\n",
        "The `ith` sample should be a Python dict with two entries: \n",
        "- `encoding` the encoding of one sentence pair, which is the concatenation of the embeddings of the two sentences of a pair. E.g., sent1 = [1,2], sent2 = [3,4], the encoding for sent1 and sent2 should be [1,2,3,4].\n",
        "- `score` the similarity score between the two sentences.\n",
        "\n",
        "**Hint**: examples can be found here: https://pytorch.org/tutorials/beginner/data_loading_tutorial.html"
      ],
      "metadata": {
        "id": "sz9EDepbxzQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLPDataset(Dataset):\n",
        "  def __init__(self, sents_1, sents_2, scores):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "      sents_1 (List[string]): the list of the first sentences.\n",
        "      sents_2 (List[string]): the list of the second sentences.\n",
        "      scores (List[float]): the list of the similarity scores.\n",
        "    \"\"\"\n",
        "    # TODO: YOUR CODE HERE\n",
        "    #initialize params\n",
        "    self.sents_1 = sents_1\n",
        "    self.sents_2 = sents_2\n",
        "    self.scores = scores\n",
        "    self.word_embedding_dict = word_embedding_dict\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    # TODO: YOUR CODE HERE\n",
        "    #get the embeddings of the sentences as a normal list\n",
        "    s1_embedding = embed_sentence(self.sents_1[idx], self.word_embedding_dict).tolist()\n",
        "    s2_embedding = embed_sentence(self.sents_2[idx], self.word_embedding_dict).tolist()\n",
        "\n",
        "    encoding = np.array(s1_embedding + s2_embedding)\n",
        "\n",
        "    return {\n",
        "        \"encoding\": encoding,\n",
        "        \"score\": self.scores[idx]\n",
        "    }\n",
        "\n",
        "  def __len__(self):\n",
        "    # TODO: YOUR CODE HERE\n",
        "    return len(self.sents_1)"
      ],
      "metadata": {
        "id": "vStUZaVtpQFy"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b)\n",
        "Instantiate the above class for our `train_set` and `dev_set`.\n",
        "\n",
        "**Print** the size of `dev_dataset` and the shape of the encoding of the first example."
      ],
      "metadata": {
        "id": "lyMFDO96x83g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: YOUR CODE HERE\n",
        "train_dataset = MLPDataset(train_set[\"sentence1\"], train_set[\"sentence2\"], train_set[\"similarity_score\"])\n",
        "dev_dataset = MLPDataset(dev_set[\"sentence1\"], dev_set[\"sentence2\"], dev_set[\"similarity_score\"])"
      ],
      "metadata": {
        "id": "7mffqVQXp6LH"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset.__getitem__(2)[\"encoding\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mm4ZJuIzW5QT",
        "outputId": "12129543-e9ba-4da2-cec0-e728b5b62203"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "600"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"size of dev_dataset == {dev_dataset.__len__()}\")\n",
        "print(\"shape of encoding of the first example == \", dev_dataset.__getitem__(0)[\"encoding\"].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpPQ_89TXjFT",
        "outputId": "b799a4e1-eaa2-4905-f3a7-ba6090158524"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size of dev_dataset == 1500\n",
            "shape of encoding of the first example ==  (600,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Task 1.2: Scoring the Similarity**\n",
        "We will train a simple multi-layer perceptron (MLP) to score the similarity of the two sentences. "
      ],
      "metadata": {
        "id": "rtcT91VOowHw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 1.2.1: Build MLP using Pytorch**\n",
        "\n",
        "We will use [`pytorch.nn`](https://pytorch.org/docs/stable/nn.html) to build our MLP. \n",
        "\n",
        "Implement a class inheriting [`pytorch.nn.Module`]() for our MLP, which has the following components:\n",
        "- A [linear layer](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear) with 1,200 dimensions and [relu activation](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU) , which takes the encoding of one sentence pair as the input.\n",
        "- A [dropout layer](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout) with probability 0.1.\n",
        "- A linear layer with 600 dimensions and relu activation.\n",
        "- A dropout layer with probability 0.1.\n",
        "- A linear layer with 300 dimensions and relu activation.\n",
        "- A dropout layer with probability 0.1.\n",
        "- A linear layer with 1 dimension (output layer). \n",
        "\n",
        "**Hint**: \n",
        "- You need to override the method `forward` in this class\n",
        "- Use `nn.Sequential` to sequentialize the layers.\n",
        "- You may want to see a quick example: https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html?highlight=sequential\n"
      ],
      "metadata": {
        "id": "iVfZ6bboqx-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MLP, self).__init__()\n",
        "    # TODO: YOUR CODE HERE\n",
        "    self.sequential_layers = nn.Sequential(\n",
        "            nn.Linear(600, 1200),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(1200, 600),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(600, 300),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(300, 1)\n",
        "        )\n",
        "  def forward(self, x):\n",
        "    # TODO: YOUR CODE HERE\n",
        "    return self.sequential_layers(x)\n",
        "\n",
        "model = MLP()\n",
        "print(model)"
      ],
      "metadata": {
        "id": "5jg3wk4KrFDc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49e3ed50-2795-4d9c-ac61-36c9d270818f"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP(\n",
            "  (sequential_layers): Sequential(\n",
            "    (0): Linear(in_features=600, out_features=1200, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.1, inplace=False)\n",
            "    (3): Linear(in_features=1200, out_features=600, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Dropout(p=0.1, inplace=False)\n",
            "    (6): Linear(in_features=600, out_features=300, bias=True)\n",
            "    (7): ReLU()\n",
            "    (8): Dropout(p=0.1, inplace=False)\n",
            "    (9): Linear(in_features=300, out_features=1, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 1.2.2: Train MLP with Pytorch**\n",
        "Train the MLP with the following setups/hyperparameters:\n",
        "- [AdmW](https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html#torch.optim.AdamW) with a learning rate of 2e-3 as the  optimizer\n",
        "- [Mean Square Error](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss) as the loss function\n",
        "- batch size: 128\n",
        "- number of training epochs: 17\n"
      ],
      "metadata": {
        "id": "7IwxQMfN2ZKJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a)\n",
        "The method for training is provided below, which returns the list of the train loss at all epochs and the trained model. Please define the corresponding parameters to call this method and **plot** the training loss using `matplotlib.pyplot.plot`; with GPU the training takes about 1.5 mins for 17 epochs. \n",
        "\n",
        "**Hint**: create the dataloader for the custom datasets (`train_dataset` and `dev_dataset`) using [`torch.utils.data.DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader); reshuffle the training data at every epoch (don't forget to define the batch size for the dataloader!).\n",
        "\n"
      ],
      "metadata": {
        "id": "Hr8ev4DokuYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_dataloader, eval_dataloader, optimizer, loss_fn, num_epochs, device='cuda'):\n",
        "  \n",
        "  train_losses = []\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "\n",
        "    if epoch == 0:\n",
        "      model.eval()\n",
        "      loss_per_epoch = 0\n",
        "      for batch_data in train_dataloader:\n",
        "        with torch.no_grad():\n",
        "          predictions = model(batch_data['encoding'].to(device))\n",
        "          targets = batch_data['score'].to(device) # only if device='cuda'\n",
        "          train_loss = loss_func(predictions.squeeze(), targets)\n",
        "          loss_per_epoch += train_loss.item()\n",
        "      loss_per_epoch = loss_per_epoch/len(train_dataloader)\n",
        "      train_losses.append(loss_per_epoch)\n",
        "      print(f'\\ninital train loss: {loss_per_epoch}')\n",
        "\n",
        "    model.train()\n",
        "    loss_per_epoch = 0\n",
        "    for batch_data in train_dataloader:\n",
        "      predictions = model(batch_data['encoding'].to(device))\n",
        "      targets = batch_data['score'].to(device) # only if device='cuda'\n",
        "      train_loss = loss_func(predictions.squeeze(), targets) \n",
        "      loss_per_epoch += train_loss.item()\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      train_loss.backward()\n",
        "      optimizer.step()   \n",
        "\n",
        "    loss_per_epoch = loss_per_epoch/len(train_dataloader)\n",
        "    train_losses.append(loss_per_epoch)\n",
        "    print(f'\\n Epoch {epoch+1} train loss: {loss_per_epoch}')\n",
        "    #evaluate(model, eval_dataloader, loss_func)\n",
        "  \n",
        "  return train_losses, model\n",
        "\n"
      ],
      "metadata": {
        "id": "OOzMDTjeehq0"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seeds; do not change this!\n",
        "seed_everything(seed=999)\n",
        "\n",
        "# TODO: YOUR CODE HERE\n",
        "# ==============================================\n",
        "\n",
        "# Define the training hyperparameters\n",
        "num_epochs = 17\n",
        "batch_size = 128\n",
        "learning_rate = 2e-3\n",
        "\n",
        "# Create dataloader\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "dev_dataloader = DataLoader(dev_dataset, batch_size=batch_size)\n",
        "\n",
        "# Initialize the model\n",
        "device = 'cuda' # \"gpu\"\n",
        "model = MLP()\n",
        "model.to(device)\n",
        "\n",
        "# Define Optimizer and Loss Function\n",
        "optimizer = torch.optim.AdamW(params=model.parameters(), lr=learning_rate)\n",
        "loss_func = nn.MSELoss()\n",
        "\n",
        "train_losses, model = train(model, train_dataloader, dev_dataloader, optimizer, loss_func, num_epochs, 'cuda')\n",
        "\n",
        "# YOUR CODE FOR PLOTTING HERE\n",
        "\n",
        "# =============================================="
      ],
      "metadata": {
        "id": "CRqhCf2d3qwt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30b4afcc-67ec-4b69-faa8-711abd2d9ef7"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "inital train loss: 9.514770823865772\n",
            "\n",
            " Epoch 1 train loss: 2.904914813172703\n",
            "\n",
            " Epoch 2 train loss: 2.1431487369775124\n",
            "\n",
            " Epoch 3 train loss: 2.072098582707661\n",
            "\n",
            " Epoch 4 train loss: 2.131613265854313\n",
            "\n",
            " Epoch 5 train loss: 1.998916331229936\n",
            "\n",
            " Epoch 6 train loss: 1.8769423414890987\n",
            "\n",
            " Epoch 7 train loss: 1.8302743190834552\n",
            "\n",
            " Epoch 8 train loss: 1.7623476238473068\n",
            "\n",
            " Epoch 9 train loss: 1.6421896324308383\n",
            "\n",
            " Epoch 10 train loss: 1.563925786286195\n",
            "\n",
            " Epoch 11 train loss: 1.4352797875875705\n",
            "\n",
            " Epoch 12 train loss: 1.314662154960458\n",
            "\n",
            " Epoch 13 train loss: 1.2712593050209375\n",
            "\n",
            " Epoch 14 train loss: 1.276536739402047\n",
            "\n",
            " Epoch 15 train loss: 1.5156666619219699\n",
            "\n",
            " Epoch 16 train loss: 1.3541686304839575\n",
            "\n",
            " Epoch 17 train loss: 1.1989442933208914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE FOR PLOTTING HERE\n",
        "def plot_epochs_loss(lst_epochs, lst_train_loss):\n",
        "  plt.plot(lst_epochs, lst_train_loss, marker=\"o\")\n",
        "  plt.xticks(lst_epochs)\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Training Loss\")\n",
        "  plt.title(\"Training Loss for each Epoch\")\n",
        "  plt.show()\n",
        "\n",
        "epochs = list(range(0, 18))\n",
        "\n",
        "plot_epochs_loss(epochs, train_losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "5e_zR5jA3u1K",
        "outputId": "ec607749-39b9-4414-dca0-9f2ab78f1bf9"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b)\n",
        "Implement a method to evaluate a model which calculates the Pearson correlation between the predictions of the model and the similarity scores from the dataset.\n",
        "\n",
        "**Print** the evaluation results  of your trained model on the dev set."
      ],
      "metadata": {
        "id": "6G-VQMzJlIC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr\n",
        "def evaluate(model, eval_dataloader):\n",
        "  # TODO: YOUR CODE HERE:\n",
        "  model.eval() # this is used to set the model in evlauation mode; details see https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.eval\n",
        "  \n",
        "  with torch.no_grad(): # this is used to disable gradient calculation; details see https://pytorch.org/docs/stable/generated/torch.no_grad.html \n",
        "    for batch_data in eval_dataloader:\n",
        "      predictions = model(batch_data['encoding'].to(device))\n",
        "      targets = batch_data['score'].to(device)\n",
        "    # transform preds and targets to numpy in CPU to then use pearsonr\n",
        "    preds_numpy = p.view(-1).cpu().numpy() #reshape and put on cpu\n",
        "    targets_numpy = targets.cpu().numpy() #put on cpu\n",
        "    \n",
        "  return preds_numpy, targets_numpy, pearsonr(preds_numpy, targets_numpy)[0]\n",
        "\n",
        "preds, targets, pearson_value = evaluate(model, dev_dataloader)\n",
        "print(f\"Pearson Correlation value == {pearson_value:.6f}\")"
      ],
      "metadata": {
        "id": "fURghifFOhXg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b1d4a26-0ea0-47ad-8a69-0f2529548df5"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pearson Correlation value == 0.582735\n"
          ]
        }
      ]
    }
  ]
}