{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My Drive/Colab Notebooks/hw3"
      ],
      "metadata": {
        "id": "QiYEF-Fy92ky",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "987ba955-737c-4693-81be-48bfce8a9aec"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/Colab Notebooks/hw3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 1:  Sequence Tagging with RNNs**\n",
        "\n",
        "In this task, you will implement LSTM and Bi-LSTM architectures with PyTorch to perform part-of-speech tagging (a sequence tagging task).\n",
        "\n",
        "### **Data**\n",
        "We use a subset of the data from the CoNLL-2003 shared task on Named Entity Recognition (provided in the zip). It is pre-partioned into a training, development and test set.\n",
        "\n",
        "The dataset consists of pre-tokenized sentences where every token is annotated with a part-of-speech tag, a syntactic chunk tag and a named entity tag. In this home exercise, we only use the IOB named entity recognition tag."
      ],
      "metadata": {
        "id": "7g3LeIyQ9-kj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics import f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ],
      "metadata": {
        "id": "zEJqyHIV3bC2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed: int):\n",
        "\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.set_default_tensor_type(torch.FloatTensor) #added to avoid datatype problems"
      ],
      "metadata": {
        "id": "BRSIDcsXMSu4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_everything(seed=999)"
      ],
      "metadata": {
        "id": "_KWHF5f8MXgo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Task 1.1: Pretrained Embeddings (5p)**\n",
        "\n",
        "Download the pretrained, uncased GloVe embeddings with 6B tokens [glove.6B.zip](https://nlp.stanford.edu/projects/glove/) from Stanford.\n",
        "\n",
        "For performance reasons, we will only use the 50-dimensional embeddings **glove.6B.50d.txt**.\n",
        "\n",
        "Implement a function to read the embedding and another function to read the dataset."
      ],
      "metadata": {
        "id": "Nb1gCI-f-mJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://medium.com/analytics-vidhya/ner-tensorflow-2-2-0-9f10dcf5a0a\n",
        "\"\"\"\n",
        "  Store each sentence seperately. Each token of the sentences is stored with its corresponding IOB named entity recognition tag\n",
        "\"\"\"\n",
        "\n",
        "def split_text_label(filename):\n",
        "  f = open(filename)\n",
        "  split_labeled_text = []\n",
        "  sentence = []\n",
        "  for line in f:\n",
        "    if len(line)==0 or line.startswith('-DOCSTART') or line[0]==\"\\n\":\n",
        "       if len(sentence) > 0:\n",
        "         split_labeled_text.append(sentence)\n",
        "         sentence = []\n",
        "       continue\n",
        "    splits = line.split(' ')\n",
        "    sentence.append([splits[0],splits[-1].rstrip(\"\\n\")])\n",
        "  if len(sentence) > 0:\n",
        "    split_labeled_text.append(sentence)\n",
        "    sentence = []\n",
        "  return split_labeled_text"
      ],
      "metadata": {
        "id": "z4L2qEqct9KE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(path):\n",
        "    data = defaultdict(list)\n",
        "    label = defaultdict(list)\n",
        "    # TODO: YOUR CODE HERE\n",
        "\n",
        "    text_label = split_text_label(filename=path)\n",
        "    for idx, sent in enumerate(text_label):\n",
        "      words = []\n",
        "      iob_labels = []\n",
        "      for word_iob in sent:\n",
        "        words.append(word_iob[0]) #add word\n",
        "        iob_labels.append(word_iob[1]) #add iob tag\n",
        "\n",
        "      data[idx] = words\n",
        "      label[idx] = iob_labels\n",
        "\n",
        "    return data, label\n",
        "\n",
        "def get_pretrained_embeddings(embedding_path):\n",
        "    embeddings = defaultdict(list)\n",
        "    # TODO: YOUR CODE HERE\n",
        "    with open(\"glove.6B.50d.txt\", \"r\") as file:\n",
        "      for line in file:\n",
        "        line = line.strip()\n",
        "        word = line.split(\" \")[0]\n",
        "        vector = np.array([float(n) for n in line.split(\" \")[1:]])\n",
        "\n",
        "        embeddings[word] = vector\n",
        "\n",
        "    return embeddings"
      ],
      "metadata": {
        "id": "gmpt_ya90sJw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed = get_pretrained_embeddings(embedding_path=\"glove.6B.50d.txt\")"
      ],
      "metadata": {
        "id": "0xB0-Gc9mQXU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed[\"get\"].shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KItfD8d-mZhn",
        "outputId": "01012091-c6b9-43e8-ae03-36edda35615f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out= split_text_label(\"data/ner_eng_bio.train\")"
      ],
      "metadata": {
        "id": "L5TTPibcuKNS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJIb2BsHuPvm",
        "outputId": "4c8c6e69-3fcc-4f0e-d466-cf9d0d37922d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['BRUSSELS', 'B-LOC'], ['1996-08-22', 'O']]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data, label = read_data(\"data/ner_eng_bio.train\")"
      ],
      "metadata": {
        "id": "UeK8Sad-xvW2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7k8llI_Dx0iX",
        "outputId": "cc4eeaee-233f-4e08-f874-b6531fe27608"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsvfI0oryAje",
        "outputId": "58bfbf34-e8e3-497a-dc83-e67920b12bd1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counter = 0\n",
        "with open(\"data/ner_eng_bio.train\", \"r\") as file:\n",
        "    for line in file:\n",
        "      print(line.strip().split(\" \"))\n",
        "      if counter == 10:\n",
        "        break\n",
        "      counter += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjz1RhREhbLz",
        "outputId": "879016b7-226c-4c43-bac1-153def6144ee"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['EU', 'NNP', 'B-NP', 'B-ORG']\n",
            "['rejects', 'VBZ', 'B-VP', 'O']\n",
            "['German', 'JJ', 'B-NP', 'B-MISC']\n",
            "['call', 'NN', 'I-NP', 'O']\n",
            "['to', 'TO', 'B-VP', 'O']\n",
            "['boycott', 'VB', 'I-VP', 'O']\n",
            "['British', 'JJ', 'B-NP', 'B-MISC']\n",
            "['lamb', 'NN', 'I-NP', 'O']\n",
            "['.', '.', 'O', 'O']\n",
            "['']\n",
            "['Peter', 'NNP', 'B-NP', 'B-PER']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"dataset = defaultdict(list)\n",
        "labels = defaultdict(list)\n",
        "with open(\"data/ner_eng_bio.train\", \"r\") as file:\n",
        "    sentence = []\n",
        "    sentence_labels = []\n",
        "    for line in file:\n",
        "        line = line.strip()\n",
        "        if line == \"\":\n",
        "            if sentence:\n",
        "                for word, label in zip(sentence, sentence_labels):\n",
        "                    dataset[\"words\"].append(word)\n",
        "                    labels[\"tags\"].append(label)\n",
        "            sentence = []\n",
        "            sentence_labels = []\n",
        "        else:\n",
        "            word, _, _, label = line.split()\n",
        "            sentence.append(word)\n",
        "            sentence_labels.append(label)\"\"\""
      ],
      "metadata": {
        "id": "E0CcQMKRjvkx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "1cd1afe4-1979-4f0c-dbdd-9e187449c8ae"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dataset = defaultdict(list)\\nlabels = defaultdict(list)\\nwith open(\"data/ner_eng_bio.train\", \"r\") as file:\\n    sentence = []\\n    sentence_labels = []\\n    for line in file:\\n        line = line.strip()\\n        if line == \"\":\\n            if sentence:\\n                for word, label in zip(sentence, sentence_labels):\\n                    dataset[\"words\"].append(word)\\n                    labels[\"tags\"].append(label)\\n            sentence = []\\n            sentence_labels = []\\n        else:\\n            word, _, _, label = line.split()\\n            sentence.append(word)\\n            sentence_labels.append(label)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Task 1.2: LSTM and Bi-LSTM Model (10p)**\n",
        "\n",
        "We will use PyTorch to build our LSTM. Complete the `__init__()` and the `forward()` function of the CustomLSTM class. The model will have the following components:\n",
        "- A single [LSTM](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html) layer which takes the embeddings as input and has 100-dimensional hidden layer. The LSTM is **not** bidirectional.\n",
        "- A dropout layer with probability 0.1\n",
        "- A linear layer with input size of 100 (the hidden layer size of the LSTM layer) and output size of the number of labels\n",
        "- A [Sigmoid](https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html) activation function"
      ],
      "metadata": {
        "id": "fCdGcnwv_f7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules import dropout\n",
        "class CustomLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_labels):\n",
        "        super(CustomLSTM, self).__init__()\n",
        "        # TODO: YOUR CODE HERE\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.num_labels = num_labels\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, dropout=0.1, bidirectional=False)\n",
        "        self.linear = nn.Linear(in_features=100, out_features=num_labels) # replace 100 with hidden_size maybe\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO: YOUR CODE HERE\n",
        "        #LSTMâ€™s output corresponding to all timesteps\n",
        "        output, (h_n, c_n) = self.lstm(x)\n",
        "        last_hidden_state = output[-1] # can also be h_n   see https://towardsdatascience.com/implementation-differences-in-lstm-layers-tensorflow-vs-pytorch-77a31d742f74#:~:text=The%20output%20of%20the%20Pytorch,another%20tuple%20with%20two%20elements.\n",
        "        linear_output = self.linear(last_hidden_state)\n",
        "        output = self.sigmoid(linear_output)\n",
        "        \n",
        "        return output"
      ],
      "metadata": {
        "id": "Z9QoXzQSoiBS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Task 1.3: Training Model (10p)**\n",
        "\n",
        "Complete the function `train` to train your model. The model will train with batch size of 1 (each sentence split by \"\\n\" is a sample) for 10 epochs. You will train the model with the train dataset and use dev dataset to check the model's performance after each epoch. Calculate the macro f1 score of the model on the dev set. Return the losses and f1 scores for plotting.\n",
        "\n",
        "**Hint**: you can check out this [link](https://pytorch.org/tutorials/beginner/introyt/trainingyt.html#the-training-loop) to get to know more about how to train model with pytorch. For the f1 score you can use `sklearn.metrics.f1_score`, remember to set the `average` parameter to \"macro\".\n"
      ],
      "metadata": {
        "id": "egNWahhpoiu_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def label_encode(labels):\n",
        "    labels_list = {'B-LOC': 0, 'B-MISC': 1, 'B-ORG': 2, 'B-PER': 3, 'I-LOC': 4, 'I-MISC': 5, 'I-ORG': 6, 'I-PER': 7,\n",
        "                   'O': 8}\n",
        "    labels_encode = [labels_list[label] for label in labels]\n",
        "    return labels_encode"
      ],
      "metadata": {
        "id": "fQLhObb_HJn0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change this to your path to the dataset\n",
        "train = \"data/ner_eng_bio.train\" \n",
        "test = \"data/ner_eng_bio.test\"\n",
        "dev = \"data/ner_eng_bio.dev\"\n",
        "\n",
        "embeddings = get_pretrained_embeddings(\"embeddings/glove.6B.50d.txt\")\n",
        "\n",
        "train_data, train_label = read_data(train)\n",
        "test_data, test_label = read_data(test)\n",
        "dev_data, dev_label = read_data(dev)\n",
        "\n",
        "EMBEDDING_SIZE = embeddings[\"get\"].shape[0]\n",
        "\n",
        "# Change the Hyperparameters here\n",
        "input_size = EMBEDDING_SIZE\n",
        "hidden_size = 100\n",
        "num_layers = 2\n",
        "num_labels = 9\n",
        "epochs = 10"
      ],
      "metadata": {
        "id": "Jg4WnZx2dej3"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_data[0], dev_label[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfLhKkt6Yl19",
        "outputId": "4401eada-e840-47d7-d678-73ae6ff29524"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['SOCCER',\n",
              "  '-',\n",
              "  'JAPAN',\n",
              "  'GET',\n",
              "  'LUCKY',\n",
              "  'WIN',\n",
              "  ',',\n",
              "  'CHINA',\n",
              "  'IN',\n",
              "  'SURPRISE',\n",
              "  'DEFEAT',\n",
              "  '.'],\n",
              " ['O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O'])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KP5VvMMxw4Im",
        "outputId": "d7236cb6-1cd2-4e74-9d22-d82b4bb6ca14"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CRICKET',\n",
              " '-',\n",
              " 'LEICESTERSHIRE',\n",
              " 'TAKE',\n",
              " 'OVER',\n",
              " 'AT',\n",
              " 'TOP',\n",
              " 'AFTER',\n",
              " 'INNINGS',\n",
              " 'VICTORY',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_label[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rcxAkdfw3__",
        "outputId": "8c2dd553-5040-4185-cf4f-f69c347380a8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aa = []\n",
        "bb = [1, 2, 3]\n",
        "aa.append(bb)\n",
        "aa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MPA8jit0vMv",
        "outputId": "a945d3b9-c0de-43c6-aefc-29d591d5879a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 2, 3]]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "array = np.random.random((1, 3, 50))\n",
        "array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwhI7YBx1xIK",
        "outputId": "dbbe7131-5383-403d-817e-126c8e523298"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.80342804, 0.5275223 , 0.11911147, 0.63968144, 0.09092526,\n",
              "         0.33222568, 0.42738095, 0.55438581, 0.62812652, 0.69739294,\n",
              "         0.78994969, 0.13189035, 0.34277045, 0.20155961, 0.70732423,\n",
              "         0.03339926, 0.90925004, 0.40516066, 0.76043547, 0.47375838,\n",
              "         0.28671892, 0.75129249, 0.09708994, 0.41235779, 0.28163896,\n",
              "         0.39027778, 0.87110921, 0.08124512, 0.55793117, 0.54753428,\n",
              "         0.33220307, 0.97326881, 0.2862761 , 0.5082575 , 0.14795074,\n",
              "         0.19643398, 0.84082001, 0.0037532 , 0.78262101, 0.83347772,\n",
              "         0.93790734, 0.97260166, 0.83282304, 0.06581761, 0.40379256,\n",
              "         0.37479349, 0.50750135, 0.97787696, 0.81899021, 0.18754124],\n",
              "        [0.69804812, 0.68261077, 0.99909815, 0.48263116, 0.73059268,\n",
              "         0.79518236, 0.26139168, 0.16107376, 0.69850315, 0.89950917,\n",
              "         0.91515562, 0.31244902, 0.95412616, 0.7242641 , 0.02091039,\n",
              "         0.72554552, 0.58165923, 0.9545687 , 0.74233195, 0.19750339,\n",
              "         0.94900651, 0.85836332, 0.44904621, 0.82365038, 0.99726878,\n",
              "         0.56413064, 0.5890016 , 0.42402702, 0.89548786, 0.44437266,\n",
              "         0.57723744, 0.66019353, 0.30244304, 0.02295771, 0.83766937,\n",
              "         0.31953292, 0.37552193, 0.18172362, 0.83135182, 0.18487429,\n",
              "         0.96968683, 0.69644561, 0.60566253, 0.49600661, 0.70888438,\n",
              "         0.26044186, 0.65267488, 0.62297362, 0.83609334, 0.3572364 ],\n",
              "        [0.95455374, 0.06336003, 0.86713576, 0.55147501, 0.8895871 ,\n",
              "         0.74683759, 0.20783523, 0.48823397, 0.59087233, 0.87087296,\n",
              "         0.7992923 , 0.95453522, 0.17335265, 0.106837  , 0.6271594 ,\n",
              "         0.37434512, 0.65200627, 0.68657226, 0.47579499, 0.66581477,\n",
              "         0.95350083, 0.18154475, 0.70021069, 0.44733626, 0.52452094,\n",
              "         0.09235484, 0.67210817, 0.91346847, 0.33153971, 0.96899058,\n",
              "         0.17409946, 0.05593003, 0.06077135, 0.77983371, 0.56480162,\n",
              "         0.13544652, 0.48310528, 0.65688242, 0.9341264 , 0.54312395,\n",
              "         0.28354295, 0.21861042, 0.74235601, 0.49747791, 0.16639362,\n",
              "         0.95924183, 0.35876406, 0.40036286, 0.68637717, 0.9340462 ]]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentence_embeddings(sent: list, embeddings_dict: dict):\n",
        "  out_sentence = []\n",
        "  for token in sent:\n",
        "    if token in embeddings_dict.keys():\n",
        "      out_sentence.append(embeddings_dict[token])\n",
        "    else:\n",
        "      out_sentence.append(np.array([0]*50))\n",
        "  return out_sentence"
      ],
      "metadata": {
        "id": "9YSRGd8M0eG3"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outt = get_sentence_embeddings(sent=train_data[0], embeddings_dict=embeddings)"
      ],
      "metadata": {
        "id": "xPr4KFx_ECd6"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oohGZHPyEi0o",
        "outputId": "697e00bd-3aec-43af-9291-185f985220ea"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4434"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor(np.array([outt])).size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AODdS3moENtU",
        "outputId": "24e0fe50-2d8a-42e9-8c40-121b7212d365"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 9, 50])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor([[[1, 2, 3, 4]]]).size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GU4q4iuDOXK",
        "outputId": "4750f406-346a-42cd-a084-a19e494ef035"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomLSTM(input_size, hidden_size, num_layers, num_labels)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters()) \n",
        "\n",
        "def train(model, loss_fn, optimizer, train_data, dev_data, train_label, dev_label, epochs):\n",
        "    logs_loss = []\n",
        "    logs_f1_score = []\n",
        "\n",
        "    # Training\n",
        "    for epoch in range(epochs):\n",
        "        # Train with train set\n",
        "        model.train()\n",
        "        # TODO: YOUR CODE HERE\n",
        "        print('EPOCH {}:'.format(epoch + 1))\n",
        "        train_loss = 0.0\n",
        "\n",
        "        for k, sent in train_data.items():\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "\n",
        "          sent_embedding = get_sentence_embeddings(sent=sent, embeddings_dict=embeddings)\n",
        "          input_data = torch.tensor(np.array([sent_embedding]), dtype=torch.float32) # Remove the last label\n",
        "          targets = torch.tensor(label_encode(train_label[k]))\n",
        "\n",
        "          # Forward pass\n",
        "          outputs = model(input_data)\n",
        "          loss = loss_fn(outputs, targets)\n",
        "\n",
        "          # Backward pass and optimization\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          train_loss += loss.item()\n",
        "        average_loss = train_loss / len(train_data) #calculate average loss value of the whole dataset\n",
        "        logs_loss.append(average_loss)\n",
        "\n",
        "        print(f\"Finished epoch {epoch+1}\")\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "        # Evaluate with dev set\n",
        "        \"\"\"with torch.no_grad():\n",
        "            model.eval()\n",
        "            # TODO: YOUR CODE HERE\n",
        "            dev_loss = 0.0\n",
        "            dev_preds = []\n",
        "            dev_targets = []\n",
        "\n",
        "            for k, sent in dev_data.items():\n",
        "              sent_embedding_dev = get_sentence_embeddings(sent=sent, embeddings_dict=embeddings)\n",
        "              input_data_dev = torch.tensor(np.array([sent_embedding_dev]), dtype=torch.float32) # Remove the last label\n",
        "              targets = torch.tensor(label_encode(dev_label[k]))\n",
        "\n",
        "              # Forward pass\n",
        "              outputs = model(input_data)\n",
        "              loss = loss_fn(outputs, targets)\n",
        "              dev_loss += loss.item()\n",
        "\n",
        "              # Convert predictions and targets to numpy arrays\n",
        "              predictions = torch.argmax(outputs, dim=1).numpy()\n",
        "              targets = targets.numpy()\n",
        "\n",
        "              dev_preds.extend(predictions)\n",
        "              dev_targets.extend(targets)\n",
        "            \n",
        "            average_dev_loss = dev_loss / len(dev_data)\n",
        "\n",
        "            # Calculate macro F1 score\n",
        "            f1 = f1_score(dev_targets, dev_preds, average='macro')\n",
        "            logs_f1_score.append(f1)\n",
        "\n",
        "            print(f\"Epoch {epoch+1}/{epochs}: Train Loss: {average_loss:.4f} | Dev Loss: {average_dev_loss:.4f} | Macro F1 Score: {f1:.4f}\")\"\"\"\n",
        "\n",
        "            # Evaluate with dev set\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            dev_loss = 0.0\n",
        "            dev_preds = []\n",
        "            dev_targets = []\n",
        "\n",
        "            for k, sent in dev_data.items():\n",
        "                sent_embedding_dev = get_sentence_embeddings(sent=sent, embeddings_dict=embeddings)\n",
        "                input_data_dev = torch.tensor(np.array([sent_embedding_dev]), dtype=torch.float32)\n",
        "                targets = torch.tensor(label_encode(dev_label[k]))\n",
        "                print(f\"targets == {targets}\")\n",
        "                print(f\"outputs == {outputs}\")\n",
        "\n",
        "                print(f\"targets shape == {targets.size()}\")\n",
        "                print(f\"outputs shape== {outputs.size()}\")\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(input_data_dev)\n",
        "                loss = loss_fn(outputs, targets)\n",
        "                dev_loss += loss.item()\n",
        "\n",
        "                # Convert predictions and targets to numpy arrays\n",
        "                predictions = torch.argmax(outputs, dim=1).numpy()\n",
        "                targets = targets.squeeze().numpy()  # Squeeze the tensor to match the batch size\n",
        "\n",
        "                dev_preds.extend(predictions)\n",
        "                dev_targets.extend(targets)\n",
        "            \n",
        "            average_dev_loss = dev_loss / len(dev_data)\n",
        "\n",
        "            # Calculate macro F1 score\n",
        "            f1 = f1_score(dev_targets, dev_preds, average='macro')\n",
        "            logs_f1_score.append(f1)\n",
        "\n",
        "            print(f\"Epoch {epoch+1}/{epochs}: Train Loss: {average_loss:.4f} | Dev Loss: {average_dev_loss:.4f} | Macro F1 Score: {f1:.4f}\")\n",
        "\n",
        "\n",
        "        \n",
        "    return logs_loss, logs_f1_score\n",
        "\n",
        "logs_loss, logs_f1_score = train(model, loss_fn, optimizer, train_data, dev_data, train_label, dev_label, epochs)"
      ],
      "metadata": {
        "id": "WJreNFlF18BK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3cdbb99a-07af-4b7b-b684-9dcee2f31c6b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 1:\n",
            "Finished epoch 1\n",
            "targets == tensor([8, 8, 0, 8, 8, 8, 8, 3, 8, 8, 8, 8])\n",
            "outputs == tensor([[9.8053e-01, 2.8851e-04, 8.1864e-03, 1.9058e-01, 1.5434e-04, 1.4847e-04,\n",
            "         2.4445e-04, 2.6630e-02, 9.9980e-01],\n",
            "        [2.8801e-03, 4.4715e-07, 1.4070e-04, 1.0527e-05, 1.6215e-07, 1.1793e-07,\n",
            "         2.4897e-07, 2.8863e-07, 1.0000e+00],\n",
            "        [1.9258e-03, 3.6324e-07, 1.2095e-04, 7.3201e-06, 1.2927e-07, 9.3104e-08,\n",
            "         1.9860e-07, 1.8727e-07, 1.0000e+00],\n",
            "        [1.6932e-03, 2.9398e-07, 1.0501e-04, 6.0248e-06, 1.0274e-07, 7.3586e-08,\n",
            "         1.5913e-07, 1.4235e-07, 1.0000e+00],\n",
            "        [1.7331e-03, 3.0385e-07, 1.0737e-04, 6.2259e-06, 1.0656e-07, 7.6331e-08,\n",
            "         1.6494e-07, 1.4907e-07, 1.0000e+00],\n",
            "        [1.8395e-03, 3.6686e-07, 1.2166e-04, 7.1260e-06, 1.3075e-07, 9.4020e-08,\n",
            "         1.9944e-07, 1.8347e-07, 1.0000e+00],\n",
            "        [1.6599e-03, 2.9173e-07, 1.0445e-04, 5.9321e-06, 1.0178e-07, 7.2927e-08,\n",
            "         1.5786e-07, 1.3977e-07, 1.0000e+00],\n",
            "        [9.7832e-01, 2.3681e-04, 7.2478e-03, 1.6315e-01, 1.2490e-04, 1.2054e-04,\n",
            "         1.9812e-04, 2.0797e-02, 9.9983e-01],\n",
            "        [2.0195e-03, 3.9915e-07, 1.2895e-04, 7.9230e-06, 1.4347e-07, 1.0303e-07,\n",
            "         2.1889e-07, 2.0966e-07, 1.0000e+00],\n",
            "        [1.8248e-03, 3.3422e-07, 1.1446e-04, 6.7601e-06, 1.1832e-07, 8.4928e-08,\n",
            "         1.8185e-07, 1.6762e-07, 1.0000e+00],\n",
            "        [3.2373e-03, 9.6851e-07, 2.2625e-04, 1.7283e-05, 3.6647e-07, 2.7174e-07,\n",
            "         5.4023e-07, 6.2362e-07, 1.0000e+00],\n",
            "        [9.8073e-01, 3.1566e-04, 8.6349e-03, 1.9949e-01, 1.6903e-04, 1.6538e-04,\n",
            "         2.6647e-04, 2.9318e-02, 9.9978e-01],\n",
            "        [1.7082e-03, 2.9738e-07, 1.0582e-04, 6.0970e-06, 1.0405e-07, 7.4551e-08,\n",
            "         1.6139e-07, 1.4484e-07, 1.0000e+00],\n",
            "        [9.7289e-01, 1.9198e-04, 6.3696e-03, 1.2951e-01, 9.9572e-05, 9.5455e-05,\n",
            "         1.5865e-04, 1.4994e-02, 9.9987e-01],\n",
            "        [1.9566e-03, 3.8218e-07, 1.2511e-04, 7.5868e-06, 1.3702e-07, 9.8400e-08,\n",
            "         2.0873e-07, 1.9837e-07, 1.0000e+00],\n",
            "        [2.4071e-03, 4.0088e-07, 1.2948e-04, 8.8542e-06, 1.4400e-07, 1.0428e-07,\n",
            "         2.2142e-07, 2.3225e-07, 1.0000e+00],\n",
            "        [1.8483e-03, 3.3495e-07, 1.1492e-04, 6.8329e-06, 1.1879e-07, 8.5181e-08,\n",
            "         1.8295e-07, 1.6931e-07, 1.0000e+00],\n",
            "        [1.8609e-03, 3.3445e-07, 1.1466e-04, 6.8506e-06, 1.1864e-07, 8.5070e-08,\n",
            "         1.8243e-07, 1.6990e-07, 1.0000e+00],\n",
            "        [1.7348e-03, 3.2015e-07, 1.1129e-04, 6.3998e-06, 1.1266e-07, 8.0891e-08,\n",
            "         1.7359e-07, 1.5621e-07, 1.0000e+00],\n",
            "        [2.0767e-03, 3.5778e-07, 1.2040e-04, 7.6191e-06, 1.2754e-07, 9.1812e-08,\n",
            "         1.9645e-07, 1.9375e-07, 1.0000e+00],\n",
            "        [1.7497e-03, 3.1102e-07, 1.0908e-04, 6.3305e-06, 1.0925e-07, 7.8366e-08,\n",
            "         1.6888e-07, 1.5292e-07, 1.0000e+00],\n",
            "        [9.8023e-01, 3.2003e-04, 8.6960e-03, 1.9861e-01, 1.7186e-04, 1.6630e-04,\n",
            "         2.7213e-04, 2.8963e-02, 9.9977e-01],\n",
            "        [1.9253e-03, 3.6554e-07, 1.2140e-04, 7.3388e-06, 1.3029e-07, 9.3642e-08,\n",
            "         1.9982e-07, 1.8818e-07, 1.0000e+00],\n",
            "        [2.2352e-03, 4.2210e-07, 1.3347e-04, 8.6943e-06, 1.5231e-07, 1.0996e-07,\n",
            "         2.3307e-07, 2.3374e-07, 1.0000e+00],\n",
            "        [2.5292e-03, 6.3390e-07, 1.7379e-04, 1.1655e-05, 2.3524e-07, 1.7211e-07,\n",
            "         3.4897e-07, 3.6711e-07, 1.0000e+00],\n",
            "        [1.7383e-03, 3.0837e-07, 1.0852e-04, 6.2865e-06, 1.0829e-07, 7.7624e-08,\n",
            "         1.6744e-07, 1.5129e-07, 1.0000e+00]], grad_fn=<SigmoidBackward0>)\n",
            "targets shape == torch.Size([12])\n",
            "outputs shape== torch.Size([26, 9])\n",
            "targets == tensor([3, 7])\n",
            "outputs == tensor([[9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [1.8161e-03, 3.2523e-07, 1.1120e-04, 6.4414e-06, 1.1490e-07, 8.2425e-08,\n",
            "         1.7707e-07, 1.6159e-07, 1.0000e+00],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [2.0489e-03, 3.8625e-07, 1.2462e-04, 7.6252e-06, 1.3869e-07, 9.9769e-08,\n",
            "         2.1201e-07, 2.0388e-07, 1.0000e+00],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [1.7902e-03, 3.2148e-07, 1.1031e-04, 6.3473e-06, 1.1342e-07, 8.1319e-08,\n",
            "         1.7495e-07, 1.5857e-07, 1.0000e+00]])\n",
            "targets shape == torch.Size([2])\n",
            "outputs shape== torch.Size([12, 9])\n",
            "targets == tensor([0, 8, 0, 4, 4, 8])\n",
            "outputs == tensor([[9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1809e-02, 9.9983e-01],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1809e-02, 9.9983e-01]])\n",
            "targets shape == torch.Size([6])\n",
            "outputs shape== torch.Size([2, 9])\n",
            "targets == tensor([0, 8, 8, 8, 8, 8, 1, 5, 8, 8, 8, 8, 8, 8, 8, 0, 8, 8, 8, 8, 8, 8, 8, 8,\n",
            "        8])\n",
            "outputs == tensor([[9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [2.0489e-03, 3.8625e-07, 1.2462e-04, 7.6252e-06, 1.3869e-07, 9.9769e-08,\n",
            "         2.1201e-07, 2.0388e-07, 1.0000e+00],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01]])\n",
            "targets shape == torch.Size([25])\n",
            "outputs shape== torch.Size([6, 9])\n",
            "targets == tensor([8, 0, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 0,\n",
            "        8])\n",
            "outputs == tensor([[9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [1.9059e-03, 3.7528e-07, 1.2219e-04, 7.1740e-06, 1.3408e-07, 9.6477e-08,\n",
            "         2.0495e-07, 1.8979e-07, 1.0000e+00],\n",
            "        [1.8181e-03, 3.3307e-07, 1.1287e-04, 6.5352e-06, 1.1786e-07, 8.4555e-08,\n",
            "         1.8135e-07, 1.6536e-07, 1.0000e+00],\n",
            "        [2.3152e-03, 4.5790e-07, 1.3955e-04, 9.0328e-06, 1.6686e-07, 1.2062e-07,\n",
            "         2.5284e-07, 2.5647e-07, 1.0000e+00],\n",
            "        [1.8721e-03, 3.4676e-07, 1.1590e-04, 6.7999e-06, 1.2322e-07, 8.8440e-08,\n",
            "         1.8910e-07, 1.7473e-07, 1.0000e+00],\n",
            "        [1.6705e-03, 2.9341e-07, 1.0364e-04, 5.7921e-06, 1.0246e-07, 7.3396e-08,\n",
            "         1.5875e-07, 1.3983e-07, 1.0000e+00],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [1.9520e-03, 3.4043e-07, 1.1489e-04, 6.9009e-06, 1.2092e-07, 8.6770e-08,\n",
            "         1.8624e-07, 1.7540e-07, 1.0000e+00],\n",
            "        [1.7824e-03, 3.2107e-07, 1.1021e-04, 6.3269e-06, 1.1328e-07, 8.1186e-08,\n",
            "         1.7461e-07, 1.5798e-07, 1.0000e+00],\n",
            "        [1.7900e-03, 3.2032e-07, 1.1000e-04, 6.3335e-06, 1.1295e-07, 8.0963e-08,\n",
            "         1.7416e-07, 1.5793e-07, 1.0000e+00],\n",
            "        [2.6101e-03, 4.6560e-07, 1.4223e-04, 9.8141e-06, 1.7027e-07, 1.2303e-07,\n",
            "         2.5991e-07, 2.7871e-07, 1.0000e+00],\n",
            "        [1.8158e-03, 3.0433e-07, 1.0679e-04, 6.2184e-06, 1.0669e-07, 7.6588e-08,\n",
            "         1.6581e-07, 1.5205e-07, 1.0000e+00],\n",
            "        [1.6928e-03, 2.9033e-07, 1.0300e-04, 5.8054e-06, 1.0129e-07, 7.2583e-08,\n",
            "         1.5730e-07, 1.3944e-07, 1.0000e+00],\n",
            "        [1.6259e-03, 2.8138e-07, 1.0066e-04, 5.5706e-06, 9.7727e-08, 7.0031e-08,\n",
            "         1.5191e-07, 1.3232e-07, 1.0000e+00],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [1.7444e-03, 3.0829e-07, 1.0718e-04, 6.1090e-06, 1.0827e-07, 7.7627e-08,\n",
            "         1.6742e-07, 1.5019e-07, 1.0000e+00],\n",
            "        [1.7900e-03, 3.2032e-07, 1.1000e-04, 6.3335e-06, 1.1295e-07, 8.0963e-08,\n",
            "         1.7416e-07, 1.5793e-07, 1.0000e+00],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [2.1453e-03, 3.6217e-07, 1.2003e-04, 7.5608e-06, 1.2919e-07, 9.3061e-08,\n",
            "         1.9941e-07, 1.9586e-07, 1.0000e+00],\n",
            "        [1.6178e-03, 2.7644e-07, 9.9463e-05, 5.5018e-06, 9.5809e-08, 6.8650e-08,\n",
            "         1.4915e-07, 1.2980e-07, 1.0000e+00],\n",
            "        [1.6719e-03, 2.9290e-07, 1.0351e-04, 5.7889e-06, 1.0226e-07, 7.3273e-08,\n",
            "         1.5852e-07, 1.3965e-07, 1.0000e+00],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [1.7902e-03, 3.2148e-07, 1.1031e-04, 6.3473e-06, 1.1342e-07, 8.1319e-08,\n",
            "         1.7495e-07, 1.5857e-07, 1.0000e+00]])\n",
            "targets shape == torch.Size([25])\n",
            "outputs shape== torch.Size([25, 9])\n",
            "targets == tensor([0, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 8, 3, 7, 8, 8, 8, 8,\n",
            "        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 8, 8, 8, 8, 8, 8, 8])\n",
            "outputs == tensor([[9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [1.8620e-03, 3.4218e-07, 1.1502e-04, 6.7255e-06, 1.2137e-07, 8.7176e-08,\n",
            "         1.8671e-07, 1.7206e-07, 1.0000e+00],\n",
            "        [1.6705e-03, 2.9341e-07, 1.0364e-04, 5.7921e-06, 1.0246e-07, 7.3396e-08,\n",
            "         1.5875e-07, 1.3983e-07, 1.0000e+00],\n",
            "        [3.0371e-03, 5.7282e-07, 1.6255e-04, 1.2091e-05, 2.1282e-07, 1.5461e-07,\n",
            "         3.2169e-07, 3.6992e-07, 1.0000e+00],\n",
            "        [7.3847e-03, 3.0437e-06, 4.5996e-04, 5.2951e-05, 1.2267e-06, 9.4965e-07,\n",
            "         1.7507e-06, 2.7731e-06, 1.0000e+00],\n",
            "        [1.6607e-03, 2.9307e-07, 1.0355e-04, 5.7672e-06, 1.0229e-07, 7.3281e-08,\n",
            "         1.5853e-07, 1.3915e-07, 1.0000e+00],\n",
            "        [1.7444e-03, 3.0829e-07, 1.0718e-04, 6.1090e-06, 1.0827e-07, 7.7627e-08,\n",
            "         1.6742e-07, 1.5019e-07, 1.0000e+00],\n",
            "        [1.8181e-03, 3.3307e-07, 1.1287e-04, 6.5352e-06, 1.1786e-07, 8.4555e-08,\n",
            "         1.8135e-07, 1.6536e-07, 1.0000e+00],\n",
            "        [1.6554e-03, 2.8410e-07, 1.0138e-04, 5.6609e-06, 9.8816e-08, 7.0818e-08,\n",
            "         1.5359e-07, 1.3493e-07, 1.0000e+00],\n",
            "        [1.6178e-03, 2.7644e-07, 9.9463e-05, 5.5018e-06, 9.5809e-08, 6.8650e-08,\n",
            "         1.4915e-07, 1.2980e-07, 1.0000e+00],\n",
            "        [1.8721e-03, 3.4676e-07, 1.1590e-04, 6.7999e-06, 1.2322e-07, 8.8440e-08,\n",
            "         1.8910e-07, 1.7473e-07, 1.0000e+00],\n",
            "        [1.8181e-03, 3.3307e-07, 1.1287e-04, 6.5352e-06, 1.1786e-07, 8.4555e-08,\n",
            "         1.8135e-07, 1.6536e-07, 1.0000e+00],\n",
            "        [2.0678e-03, 4.2257e-07, 1.3207e-04, 8.0514e-06, 1.5260e-07, 1.0993e-07,\n",
            "         2.3171e-07, 2.2204e-07, 1.0000e+00],\n",
            "        [2.0489e-03, 3.8625e-07, 1.2462e-04, 7.6252e-06, 1.3869e-07, 9.9769e-08,\n",
            "         2.1201e-07, 2.0388e-07, 1.0000e+00],\n",
            "        [1.9109e-03, 3.6300e-07, 1.1968e-04, 7.0523e-06, 1.2915e-07, 9.2868e-08,\n",
            "         1.9833e-07, 1.8422e-07, 1.0000e+00],\n",
            "        [1.6912e-03, 2.9736e-07, 1.0461e-04, 5.8785e-06, 1.0402e-07, 7.4533e-08,\n",
            "         1.6111e-07, 1.4263e-07, 1.0000e+00],\n",
            "        [1.7900e-03, 3.2032e-07, 1.1000e-04, 6.3335e-06, 1.1295e-07, 8.0963e-08,\n",
            "         1.7416e-07, 1.5793e-07, 1.0000e+00],\n",
            "        [1.9525e-03, 3.5182e-07, 1.1748e-04, 7.0257e-06, 1.2532e-07, 9.0053e-08,\n",
            "         1.9262e-07, 1.8133e-07, 1.0000e+00],\n",
            "        [1.8721e-03, 3.1363e-07, 1.0909e-04, 6.4408e-06, 1.1031e-07, 7.9230e-08,\n",
            "         1.7126e-07, 1.5927e-07, 1.0000e+00],\n",
            "        [1.7241e-03, 3.0235e-07, 1.0586e-04, 5.9986e-06, 1.0591e-07, 7.5917e-08,\n",
            "         1.6403e-07, 1.4635e-07, 1.0000e+00],\n",
            "        [1.6912e-03, 2.9736e-07, 1.0461e-04, 5.8785e-06, 1.0402e-07, 7.4533e-08,\n",
            "         1.6111e-07, 1.4263e-07, 1.0000e+00],\n",
            "        [5.9539e-03, 1.0158e-06, 2.3991e-04, 2.5490e-05, 3.9769e-07, 2.9471e-07,\n",
            "         5.9565e-07, 9.3562e-07, 1.0000e+00],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [1.7902e-03, 3.2148e-07, 1.1031e-04, 6.3473e-06, 1.1342e-07, 8.1319e-08,\n",
            "         1.7495e-07, 1.5857e-07, 1.0000e+00]])\n",
            "targets shape == torch.Size([42])\n",
            "outputs shape== torch.Size([25, 9])\n",
            "targets == tensor([3, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8])\n",
            "outputs == tensor([[9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [2.1311e-03, 4.4336e-07, 1.3644e-04, 8.4235e-06, 1.6077e-07, 1.1599e-07,\n",
            "         2.4353e-07, 2.3673e-07, 1.0000e+00],\n",
            "        [1.8114e-03, 3.3612e-07, 1.1372e-04, 6.5480e-06, 1.1917e-07, 8.5433e-08,\n",
            "         1.8298e-07, 1.6638e-07, 1.0000e+00],\n",
            "        [1.8721e-03, 3.4676e-07, 1.1590e-04, 6.7999e-06, 1.2322e-07, 8.8440e-08,\n",
            "         1.8910e-07, 1.7473e-07, 1.0000e+00],\n",
            "        [1.8181e-03, 3.3307e-07, 1.1287e-04, 6.5352e-06, 1.1786e-07, 8.4555e-08,\n",
            "         1.8135e-07, 1.6536e-07, 1.0000e+00],\n",
            "        [1.6178e-03, 2.7644e-07, 9.9463e-05, 5.5018e-06, 9.5809e-08, 6.8650e-08,\n",
            "         1.4915e-07, 1.2980e-07, 1.0000e+00],\n",
            "        [1.9594e-03, 3.8013e-07, 1.2322e-04, 7.3538e-06, 1.3618e-07, 9.7819e-08,\n",
            "         2.0792e-07, 1.9554e-07, 1.0000e+00],\n",
            "        [1.8620e-03, 3.4218e-07, 1.1502e-04, 6.7255e-06, 1.2137e-07, 8.7176e-08,\n",
            "         1.8671e-07, 1.7206e-07, 1.0000e+00],\n",
            "        [1.8537e-03, 3.5774e-07, 1.1839e-04, 6.8706e-06, 1.2738e-07, 9.1459e-08,\n",
            "         1.9493e-07, 1.7857e-07, 1.0000e+00],\n",
            "        [1.7203e-03, 3.0290e-07, 1.0603e-04, 5.9983e-06, 1.0617e-07, 7.6101e-08,\n",
            "         1.6435e-07, 1.4657e-07, 1.0000e+00],\n",
            "        [1.7798e-03, 3.1755e-07, 1.0946e-04, 6.2832e-06, 1.1174e-07, 8.0214e-08,\n",
            "         1.7276e-07, 1.5625e-07, 1.0000e+00],\n",
            "        [1.6506e-03, 2.8519e-07, 1.0163e-04, 5.6644e-06, 9.9256e-08, 7.1128e-08,\n",
            "         1.5419e-07, 1.3522e-07, 1.0000e+00],\n",
            "        [1.8181e-03, 3.3307e-07, 1.1287e-04, 6.5352e-06, 1.1786e-07, 8.4555e-08,\n",
            "         1.8135e-07, 1.6536e-07, 1.0000e+00],\n",
            "        [7.3020e-01, 9.2024e-06, 1.0256e-03, 4.6272e-03, 3.9995e-06, 3.4155e-06,\n",
            "         6.8128e-06, 1.9012e-04, 9.9999e-01],\n",
            "        [1.6596e-03, 2.8709e-07, 1.0215e-04, 5.7020e-06, 9.9956e-08, 7.1639e-08,\n",
            "         1.5527e-07, 1.3653e-07, 1.0000e+00],\n",
            "        [1.7447e-03, 3.1040e-07, 1.0772e-04, 6.1321e-06, 1.0906e-07, 7.8206e-08,\n",
            "         1.6865e-07, 1.5119e-07, 1.0000e+00],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [3.3218e-03, 6.0024e-07, 1.6780e-04, 1.3241e-05, 2.2402e-07, 1.6380e-07,\n",
            "         3.3962e-07, 4.0859e-07, 1.0000e+00],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [1.8639e-03, 3.3685e-07, 1.1381e-04, 6.6778e-06, 1.1937e-07, 8.5742e-08,\n",
            "         1.8383e-07, 1.6969e-07, 1.0000e+00],\n",
            "        [1.7723e-03, 3.1600e-07, 1.0916e-04, 6.2488e-06, 1.1135e-07, 7.9799e-08,\n",
            "         1.7177e-07, 1.5525e-07, 1.0000e+00],\n",
            "        [1.8721e-03, 3.4676e-07, 1.1590e-04, 6.7999e-06, 1.2322e-07, 8.8440e-08,\n",
            "         1.8910e-07, 1.7473e-07, 1.0000e+00],\n",
            "        [1.7900e-03, 3.2032e-07, 1.1000e-04, 6.3335e-06, 1.1295e-07, 8.0963e-08,\n",
            "         1.7416e-07, 1.5793e-07, 1.0000e+00],\n",
            "        [2.2806e-02, 2.3205e-06, 4.1513e-04, 9.6815e-05, 9.4149e-07, 7.3863e-07,\n",
            "         1.4275e-06, 4.4443e-06, 1.0000e+00],\n",
            "        [6.6917e-03, 1.8238e-06, 3.3892e-04, 3.7822e-05, 7.2669e-07, 5.5215e-07,\n",
            "         1.0594e-06, 1.6895e-06, 1.0000e+00],\n",
            "        [2.9842e-03, 5.3564e-07, 1.5627e-04, 1.1544e-05, 1.9770e-07, 1.4399e-07,\n",
            "         3.0080e-07, 3.4508e-07, 1.0000e+00],\n",
            "        [1.6912e-03, 2.9736e-07, 1.0461e-04, 5.8785e-06, 1.0402e-07, 7.4533e-08,\n",
            "         1.6111e-07, 1.4263e-07, 1.0000e+00],\n",
            "        [4.2728e-03, 7.4819e-07, 1.9495e-04, 1.7429e-05, 2.8165e-07, 2.0809e-07,\n",
            "         4.2612e-07, 5.8235e-07, 1.0000e+00],\n",
            "        [1.8181e-03, 3.3307e-07, 1.1287e-04, 6.5352e-06, 1.1786e-07, 8.4555e-08,\n",
            "         1.8135e-07, 1.6536e-07, 1.0000e+00],\n",
            "        [2.0147e-03, 3.8137e-07, 1.2388e-04, 7.4925e-06, 1.3669e-07, 9.8323e-08,\n",
            "         2.0945e-07, 1.9950e-07, 1.0000e+00],\n",
            "        [1.6510e-03, 2.8678e-07, 1.0202e-04, 5.6814e-06, 9.9883e-08, 7.1573e-08,\n",
            "         1.5505e-07, 1.3598e-07, 1.0000e+00],\n",
            "        [1.8181e-03, 3.3307e-07, 1.1287e-04, 6.5352e-06, 1.1786e-07, 8.4555e-08,\n",
            "         1.8135e-07, 1.6536e-07, 1.0000e+00],\n",
            "        [1.7706e-03, 3.1677e-07, 1.0931e-04, 6.2517e-06, 1.1159e-07, 8.0005e-08,\n",
            "         1.7215e-07, 1.5546e-07, 1.0000e+00],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [5.2761e-03, 1.0224e-06, 2.3757e-04, 2.3740e-05, 3.9656e-07, 2.9525e-07,\n",
            "         5.9421e-07, 8.7759e-07, 1.0000e+00],\n",
            "        [1.9594e-03, 3.8013e-07, 1.2322e-04, 7.3538e-06, 1.3618e-07, 9.7819e-08,\n",
            "         2.0792e-07, 1.9554e-07, 1.0000e+00],\n",
            "        [1.7320e-03, 3.1716e-07, 1.0921e-04, 6.1761e-06, 1.1160e-07, 7.9979e-08,\n",
            "         1.7208e-07, 1.5345e-07, 1.0000e+00],\n",
            "        [1.8866e-03, 3.5247e-07, 1.1725e-04, 6.8872e-06, 1.2544e-07, 9.0022e-08,\n",
            "         1.9221e-07, 1.7796e-07, 1.0000e+00],\n",
            "        [1.8419e-03, 3.3587e-07, 1.1366e-04, 6.6174e-06, 1.1892e-07, 8.5339e-08,\n",
            "         1.8311e-07, 1.6806e-07, 1.0000e+00],\n",
            "        [1.6608e-03, 2.8643e-07, 1.0199e-04, 5.6979e-06, 9.9732e-08, 7.1472e-08,\n",
            "         1.5492e-07, 1.3637e-07, 1.0000e+00],\n",
            "        [1.7902e-03, 3.2148e-07, 1.1031e-04, 6.3473e-06, 1.1342e-07, 8.1319e-08,\n",
            "         1.7495e-07, 1.5857e-07, 1.0000e+00]])\n",
            "targets shape == torch.Size([23])\n",
            "outputs shape== torch.Size([42, 9])\n",
            "targets == tensor([8, 8, 1, 8, 8, 8, 8, 8, 1, 5, 8, 8, 8, 8, 8, 8, 8])\n",
            "outputs == tensor([[9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [1.8430e-03, 3.3420e-07, 1.1328e-04, 6.6026e-06, 1.1842e-07, 8.4942e-08,\n",
            "         1.8223e-07, 1.6734e-07, 1.0000e+00],\n",
            "        [1.9125e-03, 3.5933e-07, 1.1908e-04, 7.0162e-06, 1.2821e-07, 9.2017e-08,\n",
            "         1.9649e-07, 1.8283e-07, 1.0000e+00],\n",
            "        [1.8721e-03, 3.4676e-07, 1.1590e-04, 6.7999e-06, 1.2322e-07, 8.8440e-08,\n",
            "         1.8910e-07, 1.7473e-07, 1.0000e+00],\n",
            "        [1.8181e-03, 3.3307e-07, 1.1287e-04, 6.5352e-06, 1.1786e-07, 8.4555e-08,\n",
            "         1.8135e-07, 1.6536e-07, 1.0000e+00],\n",
            "        [1.6928e-03, 2.9033e-07, 1.0300e-04, 5.8054e-06, 1.0129e-07, 7.2583e-08,\n",
            "         1.5730e-07, 1.3944e-07, 1.0000e+00],\n",
            "        [1.7444e-03, 3.0829e-07, 1.0718e-04, 6.1090e-06, 1.0827e-07, 7.7627e-08,\n",
            "         1.6742e-07, 1.5019e-07, 1.0000e+00],\n",
            "        [1.7447e-03, 3.0973e-07, 1.0754e-04, 6.1250e-06, 1.0864e-07, 7.7943e-08,\n",
            "         1.6815e-07, 1.5078e-07, 1.0000e+00],\n",
            "        [1.6807e-03, 2.9388e-07, 1.0379e-04, 5.8181e-06, 1.0266e-07, 7.3564e-08,\n",
            "         1.5913e-07, 1.4053e-07, 1.0000e+00],\n",
            "        [2.0489e-03, 3.8625e-07, 1.2462e-04, 7.6252e-06, 1.3869e-07, 9.9769e-08,\n",
            "         2.1201e-07, 2.0388e-07, 1.0000e+00],\n",
            "        [1.7074e-03, 2.9875e-07, 1.0499e-04, 5.9254e-06, 1.0446e-07, 7.4891e-08,\n",
            "         1.6191e-07, 1.4410e-07, 1.0000e+00],\n",
            "        [1.8866e-03, 3.5247e-07, 1.1725e-04, 6.8872e-06, 1.2544e-07, 9.0022e-08,\n",
            "         1.9221e-07, 1.7796e-07, 1.0000e+00],\n",
            "        [4.0018e-03, 7.5192e-07, 1.9573e-04, 1.6678e-05, 2.8422e-07, 2.0919e-07,\n",
            "         4.2769e-07, 5.5880e-07, 1.0000e+00],\n",
            "        [1.7427e-03, 3.1531e-07, 1.0879e-04, 6.1802e-06, 1.1086e-07, 7.9524e-08,\n",
            "         1.7122e-07, 1.5329e-07, 1.0000e+00],\n",
            "        [1.8460e-03, 3.4099e-07, 1.1459e-04, 6.6798e-06, 1.2066e-07, 8.6655e-08,\n",
            "         1.8569e-07, 1.7057e-07, 1.0000e+00],\n",
            "        [1.7057e-03, 3.0521e-07, 1.0638e-04, 5.9902e-06, 1.0685e-07, 7.6646e-08,\n",
            "         1.6541e-07, 1.4676e-07, 1.0000e+00],\n",
            "        [1.6946e-03, 2.9757e-07, 1.0463e-04, 5.8896e-06, 1.0408e-07, 7.4594e-08,\n",
            "         1.6126e-07, 1.4293e-07, 1.0000e+00],\n",
            "        [1.6596e-03, 2.8985e-07, 1.0277e-04, 5.7305e-06, 1.0103e-07, 7.2393e-08,\n",
            "         1.5678e-07, 1.3771e-07, 1.0000e+00],\n",
            "        [1.9078e-03, 3.8465e-07, 1.2409e-04, 7.2652e-06, 1.3754e-07, 9.8979e-08,\n",
            "         2.0980e-07, 1.9401e-07, 1.0000e+00],\n",
            "        [1.8181e-03, 3.3307e-07, 1.1287e-04, 6.5352e-06, 1.1786e-07, 8.4555e-08,\n",
            "         1.8135e-07, 1.6536e-07, 1.0000e+00],\n",
            "        [2.2587e-03, 4.8633e-07, 1.4452e-04, 9.1694e-06, 1.7704e-07, 1.2819e-07,\n",
            "         2.6760e-07, 2.6693e-07, 1.0000e+00],\n",
            "        [1.7902e-03, 3.2148e-07, 1.1031e-04, 6.3473e-06, 1.1342e-07, 8.1319e-08,\n",
            "         1.7495e-07, 1.5857e-07, 1.0000e+00]])\n",
            "targets shape == torch.Size([17])\n",
            "outputs shape== torch.Size([23, 9])\n",
            "targets == tensor([8, 8, 8, 1, 5, 8, 8, 8, 8, 8, 0, 8, 8, 8, 8, 8, 8, 8])\n",
            "outputs == tensor([[9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [2.7498e-03, 7.0832e-07, 1.8378e-04, 1.2784e-05, 2.6481e-07, 1.9374e-07,\n",
            "         3.9348e-07, 4.2243e-07, 1.0000e+00],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [1.8288e-03, 3.3147e-07, 1.1273e-04, 6.5406e-06, 1.1754e-07, 8.4245e-08,\n",
            "         1.8074e-07, 1.6516e-07, 1.0000e+00],\n",
            "        [1.8955e-03, 3.4488e-07, 1.1551e-04, 6.8365e-06, 1.2241e-07, 8.7940e-08,\n",
            "         1.8831e-07, 1.7508e-07, 1.0000e+00],\n",
            "        [2.0202e-03, 3.8284e-07, 1.2415e-04, 7.5237e-06, 1.3739e-07, 9.8608e-08,\n",
            "         2.1012e-07, 1.9998e-07, 1.0000e+00],\n",
            "        [1.7444e-03, 3.0829e-07, 1.0718e-04, 6.1090e-06, 1.0827e-07, 7.7627e-08,\n",
            "         1.6742e-07, 1.5019e-07, 1.0000e+00],\n",
            "        [1.8866e-03, 3.5247e-07, 1.1725e-04, 6.8872e-06, 1.2544e-07, 9.0022e-08,\n",
            "         1.9221e-07, 1.7796e-07, 1.0000e+00],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [1.7318e-03, 3.0026e-07, 1.0545e-04, 5.9955e-06, 1.0517e-07, 7.5385e-08,\n",
            "         1.6305e-07, 1.4586e-07, 1.0000e+00],\n",
            "        [1.8628e-03, 3.2960e-07, 1.1247e-04, 6.5931e-06, 1.1669e-07, 8.3706e-08,\n",
            "         1.8008e-07, 1.6614e-07, 1.0000e+00],\n",
            "        [1.7241e-03, 3.0364e-07, 1.0612e-04, 6.0157e-06, 1.0649e-07, 7.6301e-08,\n",
            "         1.6472e-07, 1.4707e-07, 1.0000e+00],\n",
            "        [1.8181e-03, 3.3307e-07, 1.1287e-04, 6.5352e-06, 1.1786e-07, 8.4555e-08,\n",
            "         1.8135e-07, 1.6536e-07, 1.0000e+00],\n",
            "        [1.7224e-03, 2.9964e-07, 1.0520e-04, 5.9692e-06, 1.0493e-07, 7.5203e-08,\n",
            "         1.6256e-07, 1.4510e-07, 1.0000e+00],\n",
            "        [1.6807e-03, 2.9388e-07, 1.0379e-04, 5.8181e-06, 1.0266e-07, 7.3564e-08,\n",
            "         1.5913e-07, 1.4053e-07, 1.0000e+00],\n",
            "        [1.7902e-03, 3.2148e-07, 1.1031e-04, 6.3473e-06, 1.1342e-07, 8.1319e-08,\n",
            "         1.7495e-07, 1.5857e-07, 1.0000e+00]])\n",
            "targets shape == torch.Size([18])\n",
            "outputs shape== torch.Size([17, 9])\n",
            "targets == tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 0, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
            "        8, 8, 0, 8])\n",
            "outputs == tensor([[9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [1.8121e-03, 3.1466e-07, 1.0895e-04, 6.3198e-06, 1.1092e-07, 7.9512e-08,\n",
            "         1.7144e-07, 1.5642e-07, 1.0000e+00],\n",
            "        [1.8181e-03, 3.3307e-07, 1.1287e-04, 6.5352e-06, 1.1786e-07, 8.4555e-08,\n",
            "         1.8135e-07, 1.6536e-07, 1.0000e+00],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [1.9520e-03, 3.4043e-07, 1.1489e-04, 6.9009e-06, 1.2092e-07, 8.6770e-08,\n",
            "         1.8624e-07, 1.7540e-07, 1.0000e+00],\n",
            "        [1.6438e-03, 2.8558e-07, 1.0170e-04, 5.6536e-06, 9.9390e-08, 7.1208e-08,\n",
            "         1.5431e-07, 1.3506e-07, 1.0000e+00],\n",
            "        [1.7446e-03, 3.0958e-07, 1.0751e-04, 6.1249e-06, 1.0879e-07, 7.8008e-08,\n",
            "         1.6816e-07, 1.5085e-07, 1.0000e+00],\n",
            "        [1.7754e-03, 3.1888e-07, 1.0970e-04, 6.2891e-06, 1.1238e-07, 8.0644e-08,\n",
            "         1.7348e-07, 1.5667e-07, 1.0000e+00],\n",
            "        [2.0489e-03, 3.8625e-07, 1.2462e-04, 7.6252e-06, 1.3869e-07, 9.9769e-08,\n",
            "         2.1201e-07, 2.0388e-07, 1.0000e+00],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [1.7486e-03, 3.2013e-07, 1.1002e-04, 6.2415e-06, 1.1290e-07, 8.0892e-08,\n",
            "         1.7387e-07, 1.5572e-07, 1.0000e+00],\n",
            "        [1.7444e-03, 3.0829e-07, 1.0718e-04, 6.1090e-06, 1.0827e-07, 7.7627e-08,\n",
            "         1.6742e-07, 1.5019e-07, 1.0000e+00],\n",
            "        [1.8181e-03, 3.3307e-07, 1.1287e-04, 6.5352e-06, 1.1786e-07, 8.4555e-08,\n",
            "         1.8135e-07, 1.6536e-07, 1.0000e+00],\n",
            "        [1.7318e-03, 3.0026e-07, 1.0545e-04, 5.9955e-06, 1.0517e-07, 7.5385e-08,\n",
            "         1.6305e-07, 1.4586e-07, 1.0000e+00],\n",
            "        [1.9468e-03, 3.7422e-07, 1.2199e-04, 7.2610e-06, 1.3388e-07, 9.6151e-08,\n",
            "         2.0457e-07, 1.9178e-07, 1.0000e+00],\n",
            "        [3.3509e-03, 7.7031e-07, 1.9767e-04, 1.5122e-05, 2.9317e-07, 2.1430e-07,\n",
            "         4.3634e-07, 5.1371e-07, 1.0000e+00],\n",
            "        [1.7902e-03, 3.2148e-07, 1.1031e-04, 6.3473e-06, 1.1342e-07, 8.1319e-08,\n",
            "         1.7495e-07, 1.5857e-07, 1.0000e+00]])\n",
            "targets shape == torch.Size([28])\n",
            "outputs shape== torch.Size([18, 9])\n",
            "targets == tensor([3, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 3, 7, 8, 8, 8, 1, 8, 8, 8, 3,\n",
            "        7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8])\n",
            "outputs == tensor([[9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [1.7211e-03, 3.0099e-07, 1.0560e-04, 5.9796e-06, 1.0547e-07, 7.5577e-08,\n",
            "         1.6336e-07, 1.4575e-07, 1.0000e+00],\n",
            "        [1.6946e-03, 2.9757e-07, 1.0463e-04, 5.8896e-06, 1.0408e-07, 7.4594e-08,\n",
            "         1.6126e-07, 1.4293e-07, 1.0000e+00],\n",
            "        [6.6917e-03, 1.8238e-06, 3.3892e-04, 3.7822e-05, 7.2669e-07, 5.5215e-07,\n",
            "         1.0594e-06, 1.6895e-06, 1.0000e+00],\n",
            "        [1.6945e-03, 2.9071e-07, 1.0317e-04, 5.8121e-06, 1.0143e-07, 7.2687e-08,\n",
            "         1.5747e-07, 1.3988e-07, 1.0000e+00],\n",
            "        [1.7444e-03, 3.0829e-07, 1.0718e-04, 6.1090e-06, 1.0827e-07, 7.7627e-08,\n",
            "         1.6742e-07, 1.5019e-07, 1.0000e+00],\n",
            "        [1.8181e-03, 3.3307e-07, 1.1287e-04, 6.5352e-06, 1.1786e-07, 8.4555e-08,\n",
            "         1.8135e-07, 1.6536e-07, 1.0000e+00],\n",
            "        [1.6512e-03, 2.8378e-07, 1.0130e-04, 5.6498e-06, 9.8698e-08, 7.0752e-08,\n",
            "         1.5344e-07, 1.3463e-07, 1.0000e+00],\n",
            "        [1.5999e-03, 2.7320e-07, 9.8604e-05, 5.4314e-06, 9.4532e-08, 6.7743e-08,\n",
            "         1.4725e-07, 1.2758e-07, 1.0000e+00],\n",
            "        [1.5968e-03, 2.7157e-07, 9.8213e-05, 5.4074e-06, 9.3888e-08, 6.7287e-08,\n",
            "         1.4635e-07, 1.2673e-07, 1.0000e+00],\n",
            "        [1.7009e-03, 3.0552e-07, 1.0653e-04, 5.9851e-06, 1.0714e-07, 7.6777e-08,\n",
            "         1.6557e-07, 1.4670e-07, 1.0000e+00],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [1.6912e-03, 2.9736e-07, 1.0461e-04, 5.8785e-06, 1.0402e-07, 7.4533e-08,\n",
            "         1.6111e-07, 1.4263e-07, 1.0000e+00],\n",
            "        [1.8163e-03, 3.3758e-07, 1.1405e-04, 6.5731e-06, 1.1966e-07, 8.5819e-08,\n",
            "         1.8388e-07, 1.6731e-07, 1.0000e+00],\n",
            "        [1.6946e-03, 2.9757e-07, 1.0463e-04, 5.8896e-06, 1.0408e-07, 7.4594e-08,\n",
            "         1.6126e-07, 1.4293e-07, 1.0000e+00],\n",
            "        [1.8445e-03, 3.4477e-07, 1.1562e-04, 6.7083e-06, 1.2243e-07, 8.7864e-08,\n",
            "         1.8799e-07, 1.7216e-07, 1.0000e+00],\n",
            "        [1.9594e-03, 3.8013e-07, 1.2322e-04, 7.3538e-06, 1.3618e-07, 9.7819e-08,\n",
            "         2.0792e-07, 1.9554e-07, 1.0000e+00],\n",
            "        [1.8139e-03, 3.3065e-07, 1.1243e-04, 6.5041e-06, 1.1694e-07, 8.3874e-08,\n",
            "         1.8010e-07, 1.6423e-07, 1.0000e+00],\n",
            "        [1.6836e-03, 2.9639e-07, 1.0439e-04, 5.8512e-06, 1.0365e-07, 7.4252e-08,\n",
            "         1.6051e-07, 1.4181e-07, 1.0000e+00],\n",
            "        [1.6201e-03, 2.7871e-07, 9.9991e-05, 5.5316e-06, 9.6694e-08, 6.9284e-08,\n",
            "         1.5040e-07, 1.3092e-07, 1.0000e+00],\n",
            "        [1.6081e-03, 2.7382e-07, 9.8797e-05, 5.4541e-06, 9.4783e-08, 6.7931e-08,\n",
            "         1.4768e-07, 1.2825e-07, 1.0000e+00],\n",
            "        [1.6946e-03, 2.9757e-07, 1.0463e-04, 5.8896e-06, 1.0408e-07, 7.4594e-08,\n",
            "         1.6126e-07, 1.4293e-07, 1.0000e+00],\n",
            "        [1.6705e-03, 2.9341e-07, 1.0364e-04, 5.7921e-06, 1.0246e-07, 7.3396e-08,\n",
            "         1.5875e-07, 1.3983e-07, 1.0000e+00],\n",
            "        [1.7089e-03, 3.0225e-07, 1.0584e-04, 5.9655e-06, 1.0595e-07, 7.5924e-08,\n",
            "         1.6388e-07, 1.4565e-07, 1.0000e+00],\n",
            "        [1.8813e-03, 3.5288e-07, 1.1747e-04, 6.8823e-06, 1.2566e-07, 9.0347e-08,\n",
            "         1.9260e-07, 1.7794e-07, 1.0000e+00],\n",
            "        [1.6259e-03, 2.8138e-07, 1.0066e-04, 5.5706e-06, 9.7727e-08, 7.0031e-08,\n",
            "         1.5191e-07, 1.3232e-07, 1.0000e+00],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [1.7902e-03, 3.2148e-07, 1.1031e-04, 6.3473e-06, 1.1342e-07, 8.1319e-08,\n",
            "         1.7495e-07, 1.5857e-07, 1.0000e+00]])\n",
            "targets shape == torch.Size([38])\n",
            "outputs shape== torch.Size([28, 9])\n",
            "targets == tensor([8, 8, 8, 8, 8, 8, 8, 0, 8, 8, 8, 8])\n",
            "outputs == tensor([[9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [3.9956e-03, 5.9948e-07, 1.6978e-04, 1.4797e-05, 2.2490e-07, 1.6494e-07,\n",
            "         3.4424e-07, 4.5048e-07, 1.0000e+00],\n",
            "        [1.8181e-03, 3.3307e-07, 1.1287e-04, 6.5352e-06, 1.1786e-07, 8.4555e-08,\n",
            "         1.8135e-07, 1.6536e-07, 1.0000e+00],\n",
            "        [2.5944e-03, 4.3655e-07, 1.3615e-04, 9.4221e-06, 1.5882e-07, 1.1483e-07,\n",
            "         2.4307e-07, 2.6010e-07, 1.0000e+00],\n",
            "        [1.7444e-03, 3.0829e-07, 1.0718e-04, 6.1090e-06, 1.0827e-07, 7.7627e-08,\n",
            "         1.6742e-07, 1.5019e-07, 1.0000e+00],\n",
            "        [1.8181e-03, 3.3307e-07, 1.1287e-04, 6.5352e-06, 1.1786e-07, 8.4555e-08,\n",
            "         1.8135e-07, 1.6536e-07, 1.0000e+00],\n",
            "        [4.7919e-02, 1.5457e-06, 3.3397e-04, 1.2832e-04, 6.0356e-07, 4.7686e-07,\n",
            "         9.8335e-07, 4.4425e-06, 1.0000e+00],\n",
            "        [1.6596e-03, 2.8709e-07, 1.0215e-04, 5.7020e-06, 9.9956e-08, 7.1639e-08,\n",
            "         1.5527e-07, 1.3653e-07, 1.0000e+00],\n",
            "        [2.0489e-03, 3.8625e-07, 1.2462e-04, 7.6252e-06, 1.3869e-07, 9.9769e-08,\n",
            "         2.1201e-07, 2.0388e-07, 1.0000e+00],\n",
            "        [1.6934e-03, 2.9925e-07, 1.0504e-04, 5.9008e-06, 1.0471e-07, 7.5064e-08,\n",
            "         1.6209e-07, 1.4364e-07, 1.0000e+00],\n",
            "        [1.6912e-03, 2.9736e-07, 1.0461e-04, 5.8785e-06, 1.0402e-07, 7.4533e-08,\n",
            "         1.6111e-07, 1.4263e-07, 1.0000e+00],\n",
            "        [2.5557e-03, 5.7758e-07, 1.6156e-04, 1.0931e-05, 2.1303e-07, 1.5522e-07,\n",
            "         3.2049e-07, 3.3721e-07, 1.0000e+00],\n",
            "        [1.7900e-03, 3.2032e-07, 1.1000e-04, 6.3335e-06, 1.1295e-07, 8.0963e-08,\n",
            "         1.7416e-07, 1.5793e-07, 1.0000e+00],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [2.4976e-03, 6.1988e-07, 1.6927e-04, 1.1141e-05, 2.2986e-07, 1.6742e-07,\n",
            "         3.4289e-07, 3.5334e-07, 1.0000e+00],\n",
            "        [1.8665e-03, 3.7248e-07, 1.2155e-04, 7.0384e-06, 1.3286e-07, 9.5514e-08,\n",
            "         2.0266e-07, 1.8586e-07, 1.0000e+00],\n",
            "        [1.8181e-03, 3.3307e-07, 1.1287e-04, 6.5352e-06, 1.1786e-07, 8.4555e-08,\n",
            "         1.8135e-07, 1.6536e-07, 1.0000e+00],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [1.7861e-03, 3.2112e-07, 1.1037e-04, 6.3344e-06, 1.1332e-07, 8.1260e-08,\n",
            "         1.7482e-07, 1.5823e-07, 1.0000e+00],\n",
            "        [1.7604e-03, 3.1847e-07, 1.0956e-04, 6.2521e-06, 1.1222e-07, 8.0438e-08,\n",
            "         1.7304e-07, 1.5563e-07, 1.0000e+00],\n",
            "        [7.0386e-03, 1.4218e-06, 2.9449e-04, 3.4175e-05, 5.6451e-07, 4.2618e-07,\n",
            "         8.4132e-07, 1.4091e-06, 1.0000e+00],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [1.9765e-03, 3.9341e-07, 1.2624e-04, 7.5172e-06, 1.4118e-07, 1.0164e-07,\n",
            "         2.1535e-07, 2.0223e-07, 1.0000e+00],\n",
            "        [1.6912e-03, 2.9736e-07, 1.0461e-04, 5.8785e-06, 1.0402e-07, 7.4533e-08,\n",
            "         1.6111e-07, 1.4263e-07, 1.0000e+00],\n",
            "        [1.7491e-03, 3.1767e-07, 1.0941e-04, 6.2185e-06, 1.1191e-07, 8.0240e-08,\n",
            "         1.7257e-07, 1.5474e-07, 1.0000e+00],\n",
            "        [2.2771e-03, 4.8284e-07, 1.4424e-04, 9.1983e-06, 1.7607e-07, 1.2738e-07,\n",
            "         2.6655e-07, 2.6660e-07, 1.0000e+00],\n",
            "        [1.7764e-03, 3.2085e-07, 1.1019e-04, 6.3102e-06, 1.1316e-07, 8.1144e-08,\n",
            "         1.7449e-07, 1.5760e-07, 1.0000e+00],\n",
            "        [1.7914e-03, 3.2345e-07, 1.1076e-04, 6.3745e-06, 1.1415e-07, 8.1859e-08,\n",
            "         1.7610e-07, 1.5958e-07, 1.0000e+00],\n",
            "        [1.7009e-03, 3.0552e-07, 1.0653e-04, 5.9851e-06, 1.0714e-07, 7.6777e-08,\n",
            "         1.6557e-07, 1.4670e-07, 1.0000e+00],\n",
            "        [1.6912e-03, 2.9736e-07, 1.0461e-04, 5.8785e-06, 1.0402e-07, 7.4533e-08,\n",
            "         1.6111e-07, 1.4263e-07, 1.0000e+00],\n",
            "        [1.7447e-03, 3.0722e-07, 1.0706e-04, 6.0968e-06, 1.0777e-07, 7.7283e-08,\n",
            "         1.6684e-07, 1.4982e-07, 1.0000e+00],\n",
            "        [1.7320e-03, 3.1716e-07, 1.0921e-04, 6.1761e-06, 1.1160e-07, 7.9979e-08,\n",
            "         1.7208e-07, 1.5345e-07, 1.0000e+00],\n",
            "        [1.8181e-03, 3.3307e-07, 1.1287e-04, 6.5352e-06, 1.1786e-07, 8.4555e-08,\n",
            "         1.8135e-07, 1.6536e-07, 1.0000e+00],\n",
            "        [1.6608e-03, 2.8643e-07, 1.0199e-04, 5.6979e-06, 9.9732e-08, 7.1472e-08,\n",
            "         1.5492e-07, 1.3637e-07, 1.0000e+00],\n",
            "        [1.7902e-03, 3.2148e-07, 1.1031e-04, 6.3473e-06, 1.1342e-07, 8.1319e-08,\n",
            "         1.7495e-07, 1.5857e-07, 1.0000e+00]])\n",
            "targets shape == torch.Size([12])\n",
            "outputs shape== torch.Size([38, 9])\n",
            "targets == tensor([8, 3, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
            "        8, 8, 8, 3, 8, 8, 8])\n",
            "outputs == tensor([[9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [1.8955e-03, 3.4488e-07, 1.1551e-04, 6.8365e-06, 1.2241e-07, 8.7940e-08,\n",
            "         1.8831e-07, 1.7508e-07, 1.0000e+00],\n",
            "        [1.8181e-03, 3.3307e-07, 1.1287e-04, 6.5352e-06, 1.1786e-07, 8.4555e-08,\n",
            "         1.8135e-07, 1.6536e-07, 1.0000e+00],\n",
            "        [1.6554e-03, 2.8410e-07, 1.0138e-04, 5.6609e-06, 9.8816e-08, 7.0818e-08,\n",
            "         1.5359e-07, 1.3493e-07, 1.0000e+00],\n",
            "        [2.2827e-03, 4.2487e-07, 1.3352e-04, 8.5851e-06, 1.5430e-07, 1.1106e-07,\n",
            "         2.3456e-07, 2.3735e-07, 1.0000e+00],\n",
            "        [1.7766e-02, 2.0675e-06, 3.8169e-04, 7.6764e-05, 8.3877e-07, 6.4834e-07,\n",
            "         1.2627e-06, 3.3748e-06, 1.0000e+00],\n",
            "        [1.9919e-03, 3.9865e-07, 1.2713e-04, 7.6206e-06, 1.4332e-07, 1.0320e-07,\n",
            "         2.1825e-07, 2.0629e-07, 1.0000e+00],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [1.7444e-03, 3.0829e-07, 1.0718e-04, 6.1090e-06, 1.0827e-07, 7.7627e-08,\n",
            "         1.6742e-07, 1.5019e-07, 1.0000e+00],\n",
            "        [1.6132e-03, 2.7680e-07, 9.9513e-05, 5.4972e-06, 9.5948e-08, 6.8750e-08,\n",
            "         1.4931e-07, 1.2977e-07, 1.0000e+00],\n",
            "        [1.5968e-03, 2.7157e-07, 9.8213e-05, 5.4074e-06, 9.3888e-08, 6.7287e-08,\n",
            "         1.4635e-07, 1.2673e-07, 1.0000e+00],\n",
            "        [1.7902e-03, 3.2148e-07, 1.1031e-04, 6.3473e-06, 1.1342e-07, 8.1319e-08,\n",
            "         1.7495e-07, 1.5857e-07, 1.0000e+00]])\n",
            "targets shape == torch.Size([31])\n",
            "outputs shape== torch.Size([12, 9])\n",
            "targets == tensor([3, 7, 8, 8, 0, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8])\n",
            "outputs == tensor([[9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [1.8600e-03, 3.1599e-07, 1.0925e-04, 6.4329e-06, 1.1132e-07, 7.9907e-08,\n",
            "         1.7240e-07, 1.5928e-07, 1.0000e+00],\n",
            "        [1.6912e-03, 2.9736e-07, 1.0461e-04, 5.8785e-06, 1.0402e-07, 7.4533e-08,\n",
            "         1.6111e-07, 1.4263e-07, 1.0000e+00],\n",
            "        [3.0718e-03, 6.0044e-07, 1.6804e-04, 1.2511e-05, 2.2322e-07, 1.6276e-07,\n",
            "         3.3720e-07, 3.8919e-07, 1.0000e+00],\n",
            "        [1.7900e-03, 3.2032e-07, 1.1000e-04, 6.3335e-06, 1.1295e-07, 8.0963e-08,\n",
            "         1.7416e-07, 1.5793e-07, 1.0000e+00],\n",
            "        [1.8769e-03, 3.6146e-07, 1.1926e-04, 6.9596e-06, 1.2890e-07, 9.2564e-08,\n",
            "         1.9713e-07, 1.8176e-07, 1.0000e+00],\n",
            "        [2.0147e-03, 3.8137e-07, 1.2388e-04, 7.4925e-06, 1.3669e-07, 9.8323e-08,\n",
            "         2.0945e-07, 1.9950e-07, 1.0000e+00],\n",
            "        [1.7320e-03, 3.1716e-07, 1.0921e-04, 6.1761e-06, 1.1160e-07, 7.9979e-08,\n",
            "         1.7208e-07, 1.5345e-07, 1.0000e+00],\n",
            "        [1.8181e-03, 3.3307e-07, 1.1287e-04, 6.5352e-06, 1.1786e-07, 8.4555e-08,\n",
            "         1.8135e-07, 1.6536e-07, 1.0000e+00],\n",
            "        [2.2587e-03, 4.8633e-07, 1.4452e-04, 9.1694e-06, 1.7704e-07, 1.2819e-07,\n",
            "         2.6760e-07, 2.6693e-07, 1.0000e+00],\n",
            "        [1.7444e-03, 3.0829e-07, 1.0718e-04, 6.1090e-06, 1.0827e-07, 7.7627e-08,\n",
            "         1.6742e-07, 1.5019e-07, 1.0000e+00],\n",
            "        [1.8181e-03, 3.3307e-07, 1.1287e-04, 6.5352e-06, 1.1786e-07, 8.4555e-08,\n",
            "         1.8135e-07, 1.6536e-07, 1.0000e+00],\n",
            "        [4.7409e-02, 1.6187e-06, 3.4104e-04, 1.3072e-04, 6.3429e-07, 5.0145e-07,\n",
            "         1.0269e-06, 4.6256e-06, 1.0000e+00],\n",
            "        [1.6596e-03, 2.8709e-07, 1.0215e-04, 5.7020e-06, 9.9956e-08, 7.1639e-08,\n",
            "         1.5527e-07, 1.3653e-07, 1.0000e+00],\n",
            "        [1.7764e-03, 3.2085e-07, 1.1019e-04, 6.3102e-06, 1.1316e-07, 8.1144e-08,\n",
            "         1.7449e-07, 1.5760e-07, 1.0000e+00],\n",
            "        [1.6523e-03, 2.8621e-07, 1.0189e-04, 5.6774e-06, 9.9660e-08, 7.1398e-08,\n",
            "         1.5473e-07, 1.3575e-07, 1.0000e+00],\n",
            "        [2.0813e-03, 4.0665e-07, 1.2911e-04, 7.9262e-06, 1.4670e-07, 1.0551e-07,\n",
            "         2.2370e-07, 2.1593e-07, 1.0000e+00],\n",
            "        [1.6912e-03, 2.9736e-07, 1.0461e-04, 5.8785e-06, 1.0402e-07, 7.4533e-08,\n",
            "         1.6111e-07, 1.4263e-07, 1.0000e+00],\n",
            "        [4.3711e-03, 9.2554e-07, 2.2212e-04, 1.9854e-05, 3.5575e-07, 2.6257e-07,\n",
            "         5.2914e-07, 7.1513e-07, 1.0000e+00],\n",
            "        [1.7542e-03, 3.1655e-07, 1.0917e-04, 6.2156e-06, 1.1149e-07, 7.9901e-08,\n",
            "         1.7198e-07, 1.5443e-07, 1.0000e+00],\n",
            "        [1.7320e-03, 3.1716e-07, 1.0921e-04, 6.1761e-06, 1.1160e-07, 7.9979e-08,\n",
            "         1.7208e-07, 1.5345e-07, 1.0000e+00],\n",
            "        [1.8181e-03, 3.3307e-07, 1.1287e-04, 6.5352e-06, 1.1786e-07, 8.4555e-08,\n",
            "         1.8135e-07, 1.6536e-07, 1.0000e+00],\n",
            "        [1.8083e-03, 3.2016e-07, 1.1008e-04, 6.3741e-06, 1.1298e-07, 8.1015e-08,\n",
            "         1.7432e-07, 1.5885e-07, 1.0000e+00],\n",
            "        [4.0853e-03, 1.0783e-06, 2.4246e-04, 2.0599e-05, 4.1529e-07, 3.0873e-07,\n",
            "         6.1266e-07, 7.8757e-07, 1.0000e+00],\n",
            "        [1.8721e-03, 3.4676e-07, 1.1590e-04, 6.7999e-06, 1.2322e-07, 8.8440e-08,\n",
            "         1.8910e-07, 1.7473e-07, 1.0000e+00],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [2.1557e-03, 4.4053e-07, 1.3558e-04, 8.4542e-06, 1.5958e-07, 1.1513e-07,\n",
            "         2.4186e-07, 2.3699e-07, 1.0000e+00],\n",
            "        [1.7861e-03, 3.2112e-07, 1.1037e-04, 6.3344e-06, 1.1332e-07, 8.1260e-08,\n",
            "         1.7482e-07, 1.5823e-07, 1.0000e+00],\n",
            "        [1.7902e-03, 3.2148e-07, 1.1031e-04, 6.3473e-06, 1.1342e-07, 8.1319e-08,\n",
            "         1.7495e-07, 1.5857e-07, 1.0000e+00]])\n",
            "targets shape == torch.Size([16])\n",
            "outputs shape== torch.Size([31, 9])\n",
            "targets == tensor([0, 8, 8, 8, 8, 8, 1, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 8, 8])\n",
            "outputs == tensor([[9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [1.7849e-03, 3.1898e-07, 1.0968e-04, 6.3143e-06, 1.1239e-07, 8.0650e-08,\n",
            "         1.7357e-07, 1.5730e-07, 1.0000e+00],\n",
            "        [1.8132e-03, 3.2471e-07, 1.1108e-04, 6.4335e-06, 1.1470e-07, 8.2252e-08,\n",
            "         1.7673e-07, 1.6130e-07, 1.0000e+00],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [1.8181e-03, 3.3307e-07, 1.1287e-04, 6.5352e-06, 1.1786e-07, 8.4555e-08,\n",
            "         1.8135e-07, 1.6536e-07, 1.0000e+00],\n",
            "        [1.8336e-03, 3.2791e-07, 1.1196e-04, 6.5087e-06, 1.1600e-07, 8.3202e-08,\n",
            "         1.7883e-07, 1.6371e-07, 1.0000e+00],\n",
            "        [1.7824e-03, 3.2107e-07, 1.1021e-04, 6.3269e-06, 1.1328e-07, 8.1186e-08,\n",
            "         1.7461e-07, 1.5798e-07, 1.0000e+00],\n",
            "        [1.7900e-03, 3.2032e-07, 1.1000e-04, 6.3335e-06, 1.1295e-07, 8.0963e-08,\n",
            "         1.7416e-07, 1.5793e-07, 1.0000e+00],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [2.9842e-03, 5.3564e-07, 1.5627e-04, 1.1544e-05, 1.9770e-07, 1.4399e-07,\n",
            "         3.0080e-07, 3.4508e-07, 1.0000e+00],\n",
            "        [1.7444e-03, 3.0829e-07, 1.0718e-04, 6.1090e-06, 1.0827e-07, 7.7627e-08,\n",
            "         1.6742e-07, 1.5019e-07, 1.0000e+00],\n",
            "        [1.8181e-03, 3.3307e-07, 1.1287e-04, 6.5352e-06, 1.1786e-07, 8.4555e-08,\n",
            "         1.8135e-07, 1.6536e-07, 1.0000e+00],\n",
            "        [1.8277e-03, 3.1792e-07, 1.0966e-04, 6.3881e-06, 1.1201e-07, 8.0393e-08,\n",
            "         1.7318e-07, 1.5873e-07, 1.0000e+00],\n",
            "        [1.6596e-03, 2.8709e-07, 1.0215e-04, 5.7020e-06, 9.9956e-08, 7.1639e-08,\n",
            "         1.5527e-07, 1.3653e-07, 1.0000e+00],\n",
            "        [1.7902e-03, 3.2148e-07, 1.1031e-04, 6.3473e-06, 1.1342e-07, 8.1319e-08,\n",
            "         1.7495e-07, 1.5857e-07, 1.0000e+00]])\n",
            "targets shape == torch.Size([21])\n",
            "outputs shape== torch.Size([16, 9])\n",
            "targets == tensor([3, 8, 8, 8, 8, 8, 8, 8, 8])\n",
            "outputs == tensor([[9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [1.7914e-03, 3.2345e-07, 1.1076e-04, 6.3745e-06, 1.1415e-07, 8.1859e-08,\n",
            "         1.7610e-07, 1.5958e-07, 1.0000e+00],\n",
            "        [2.3420e-03, 4.9928e-07, 1.4742e-04, 9.5301e-06, 1.8272e-07, 1.3230e-07,\n",
            "         2.7587e-07, 2.7981e-07, 1.0000e+00],\n",
            "        [2.0545e-03, 4.1331e-07, 1.2992e-04, 7.9137e-06, 1.4822e-07, 1.0709e-07,\n",
            "         2.2599e-07, 2.1637e-07, 1.0000e+00],\n",
            "        [1.6912e-03, 2.9736e-07, 1.0461e-04, 5.8785e-06, 1.0402e-07, 7.4533e-08,\n",
            "         1.6111e-07, 1.4263e-07, 1.0000e+00],\n",
            "        [1.8181e-03, 3.3307e-07, 1.1287e-04, 6.5352e-06, 1.1786e-07, 8.4555e-08,\n",
            "         1.8135e-07, 1.6536e-07, 1.0000e+00],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [1.6641e-03, 2.9023e-07, 1.0289e-04, 5.7450e-06, 1.0118e-07, 7.2519e-08,\n",
            "         1.5706e-07, 1.3810e-07, 1.0000e+00],\n",
            "        [2.2587e-03, 4.8633e-07, 1.4452e-04, 9.1694e-06, 1.7704e-07, 1.2819e-07,\n",
            "         2.6760e-07, 2.6693e-07, 1.0000e+00],\n",
            "        [1.7241e-03, 3.0364e-07, 1.0612e-04, 6.0157e-06, 1.0649e-07, 7.6301e-08,\n",
            "         1.6472e-07, 1.4707e-07, 1.0000e+00],\n",
            "        [1.8114e-03, 3.3612e-07, 1.1372e-04, 6.5480e-06, 1.1917e-07, 8.5433e-08,\n",
            "         1.8298e-07, 1.6638e-07, 1.0000e+00],\n",
            "        [1.8721e-03, 3.4676e-07, 1.1590e-04, 6.7999e-06, 1.2322e-07, 8.8440e-08,\n",
            "         1.8910e-07, 1.7473e-07, 1.0000e+00],\n",
            "        [1.8181e-03, 3.3307e-07, 1.1287e-04, 6.5352e-06, 1.1786e-07, 8.4555e-08,\n",
            "         1.8135e-07, 1.6536e-07, 1.0000e+00],\n",
            "        [1.6367e-03, 2.8344e-07, 1.0121e-04, 5.6149e-06, 9.8520e-08, 7.0582e-08,\n",
            "         1.5311e-07, 1.3372e-07, 1.0000e+00],\n",
            "        [1.7764e-03, 3.2085e-07, 1.1019e-04, 6.3102e-06, 1.1316e-07, 8.1144e-08,\n",
            "         1.7449e-07, 1.5760e-07, 1.0000e+00],\n",
            "        [1.9356e-03, 3.7655e-07, 1.2275e-04, 7.2513e-06, 1.3479e-07, 9.6850e-08,\n",
            "         2.0589e-07, 1.9210e-07, 1.0000e+00],\n",
            "        [2.7213e-03, 5.4483e-07, 1.5692e-04, 1.1002e-05, 2.0093e-07, 1.4626e-07,\n",
            "         3.0461e-07, 3.3252e-07, 1.0000e+00],\n",
            "        [1.8181e-03, 3.3307e-07, 1.1287e-04, 6.5352e-06, 1.1786e-07, 8.4555e-08,\n",
            "         1.8135e-07, 1.6536e-07, 1.0000e+00],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [2.3152e-03, 4.5790e-07, 1.3955e-04, 9.0328e-06, 1.6686e-07, 1.2062e-07,\n",
            "         2.5284e-07, 2.5647e-07, 1.0000e+00],\n",
            "        [1.7902e-03, 3.2148e-07, 1.1031e-04, 6.3473e-06, 1.1342e-07, 8.1319e-08,\n",
            "         1.7495e-07, 1.5857e-07, 1.0000e+00]])\n",
            "targets shape == torch.Size([9])\n",
            "outputs shape== torch.Size([21, 9])\n",
            "targets == tensor([0, 8, 3, 7, 8, 8, 8, 8, 8, 1, 8, 8, 8, 8, 8, 8, 8])\n",
            "outputs == tensor([[9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [1.9218e-03, 3.5633e-07, 1.1824e-04, 7.0141e-06, 1.2683e-07, 9.1197e-08,\n",
            "         1.9499e-07, 1.8210e-07, 1.0000e+00],\n",
            "        [1.6627e-03, 2.9275e-07, 1.0346e-04, 5.7685e-06, 1.0213e-07, 7.3192e-08,\n",
            "         1.5839e-07, 1.3914e-07, 1.0000e+00],\n",
            "        [2.1411e-03, 4.0930e-07, 1.2966e-04, 8.0960e-06, 1.4785e-07, 1.0640e-07,\n",
            "         2.2532e-07, 2.2114e-07, 1.0000e+00],\n",
            "        [2.3946e-03, 4.1014e-07, 1.3098e-04, 8.6869e-06, 1.4847e-07, 1.0708e-07,\n",
            "         2.2787e-07, 2.3633e-07, 1.0000e+00],\n",
            "        [2.2874e-03, 4.7277e-07, 1.4290e-04, 9.0932e-06, 1.7253e-07, 1.2452e-07,\n",
            "         2.6115e-07, 2.6140e-07, 1.0000e+00],\n",
            "        [1.7065e-03, 3.0486e-07, 1.0640e-04, 5.9900e-06, 1.0690e-07, 7.6606e-08,\n",
            "         1.6531e-07, 1.4672e-07, 1.0000e+00],\n",
            "        [1.9231e-03, 3.6093e-07, 1.1924e-04, 7.0653e-06, 1.2872e-07, 9.2483e-08,\n",
            "         1.9740e-07, 1.8435e-07, 1.0000e+00],\n",
            "        [1.7902e-03, 3.2148e-07, 1.1031e-04, 6.3473e-06, 1.1342e-07, 8.1319e-08,\n",
            "         1.7495e-07, 1.5857e-07, 1.0000e+00]])\n",
            "targets shape == torch.Size([17])\n",
            "outputs shape== torch.Size([9, 9])\n",
            "targets == tensor([8, 1, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8])\n",
            "outputs == tensor([[9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [3.6134e-03, 7.3567e-07, 1.8987e-04, 1.5610e-05, 2.7594e-07, 2.0362e-07,\n",
            "         4.1664e-07, 5.1891e-07, 1.0000e+00],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [2.4415e-03, 5.5396e-07, 1.5731e-04, 1.0346e-05, 2.0364e-07, 1.4827e-07,\n",
            "         3.0583e-07, 3.1582e-07, 1.0000e+00],\n",
            "        [1.8755e-03, 3.3707e-07, 1.1406e-04, 6.6923e-06, 1.1962e-07, 8.5771e-08,\n",
            "         1.8404e-07, 1.7004e-07, 1.0000e+00],\n",
            "        [2.2312e-03, 4.4776e-07, 1.3744e-04, 8.7132e-06, 1.6251e-07, 1.1731e-07,\n",
            "         2.4694e-07, 2.4538e-07, 1.0000e+00],\n",
            "        [2.2312e-03, 4.4776e-07, 1.3744e-04, 8.7132e-06, 1.6251e-07, 1.1731e-07,\n",
            "         2.4694e-07, 2.4538e-07, 1.0000e+00],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [1.8829e-03, 3.6233e-07, 1.1947e-04, 6.9825e-06, 1.2927e-07, 9.2741e-08,\n",
            "         1.9757e-07, 1.8248e-07, 1.0000e+00],\n",
            "        [1.7861e-03, 3.2112e-07, 1.1037e-04, 6.3344e-06, 1.1332e-07, 8.1260e-08,\n",
            "         1.7482e-07, 1.5823e-07, 1.0000e+00],\n",
            "        [2.2087e-03, 4.3454e-07, 1.3512e-04, 8.5027e-06, 1.5776e-07, 1.1366e-07,\n",
            "         2.3939e-07, 2.3696e-07, 1.0000e+00],\n",
            "        [2.6101e-03, 4.6560e-07, 1.4223e-04, 9.8141e-06, 1.7027e-07, 1.2303e-07,\n",
            "         2.5991e-07, 2.7871e-07, 1.0000e+00],\n",
            "        [1.7241e-03, 3.0364e-07, 1.0612e-04, 6.0157e-06, 1.0649e-07, 7.6301e-08,\n",
            "         1.6472e-07, 1.4707e-07, 1.0000e+00],\n",
            "        [1.6616e-03, 2.8949e-07, 1.0272e-04, 5.7299e-06, 1.0097e-07, 7.2341e-08,\n",
            "         1.5661e-07, 1.3765e-07, 1.0000e+00],\n",
            "        [1.7902e-03, 3.2148e-07, 1.1031e-04, 6.3473e-06, 1.1342e-07, 8.1319e-08,\n",
            "         1.7495e-07, 1.5857e-07, 1.0000e+00]])\n",
            "targets shape == torch.Size([20])\n",
            "outputs shape== torch.Size([17, 9])\n",
            "targets == tensor([8])\n",
            "outputs == tensor([[9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [9.7939e-01, 2.4274e-04, 7.3275e-03, 1.6544e-01, 1.2855e-04, 1.2365e-04,\n",
            "         2.0416e-04, 2.1808e-02, 9.9983e-01],\n",
            "        [3.9956e-03, 5.9948e-07, 1.6978e-04, 1.4797e-05, 2.2490e-07, 1.6494e-07,\n",
            "         3.4424e-07, 4.5048e-07, 1.0000e+00],\n",
            "        [1.7076e-03, 3.0251e-07, 1.0584e-04, 5.9682e-06, 1.0599e-07, 7.5996e-08,\n",
            "         1.6402e-07, 1.4575e-07, 1.0000e+00],\n",
            "        [1.9594e-03, 3.8013e-07, 1.2322e-04, 7.3538e-06, 1.3618e-07, 9.7819e-08,\n",
            "         2.0792e-07, 1.9554e-07, 1.0000e+00],\n",
            "        [1.7914e-03, 3.2345e-07, 1.1076e-04, 6.3745e-06, 1.1415e-07, 8.1859e-08,\n",
            "         1.7610e-07, 1.5958e-07, 1.0000e+00],\n",
            "        [2.5848e-03, 5.0325e-07, 1.4873e-04, 1.0201e-05, 1.8488e-07, 1.3375e-07,\n",
            "         2.8048e-07, 2.9761e-07, 1.0000e+00],\n",
            "        [6.8775e-03, 1.0573e-06, 2.4867e-04, 2.8696e-05, 4.1094e-07, 3.0723e-07,\n",
            "         6.2124e-07, 1.0648e-06, 1.0000e+00],\n",
            "        [1.9594e-03, 3.8013e-07, 1.2322e-04, 7.3538e-06, 1.3618e-07, 9.7819e-08,\n",
            "         2.0792e-07, 1.9554e-07, 1.0000e+00],\n",
            "        [1.8669e-03, 3.4943e-07, 1.1675e-04, 6.8142e-06, 1.2440e-07, 8.9250e-08,\n",
            "         1.9072e-07, 1.7562e-07, 1.0000e+00],\n",
            "        [1.8769e-03, 3.6146e-07, 1.1926e-04, 6.9596e-06, 1.2890e-07, 9.2564e-08,\n",
            "         1.9713e-07, 1.8176e-07, 1.0000e+00],\n",
            "        [1.8418e-03, 3.2221e-07, 1.1070e-04, 6.4716e-06, 1.1370e-07, 8.1568e-08,\n",
            "         1.7576e-07, 1.6175e-07, 1.0000e+00],\n",
            "        [1.7604e-03, 3.1847e-07, 1.0956e-04, 6.2521e-06, 1.1222e-07, 8.0438e-08,\n",
            "         1.7304e-07, 1.5563e-07, 1.0000e+00],\n",
            "        [1.8430e-03, 3.3420e-07, 1.1328e-04, 6.6026e-06, 1.1842e-07, 8.4942e-08,\n",
            "         1.8223e-07, 1.6734e-07, 1.0000e+00],\n",
            "        [1.7542e-03, 3.1655e-07, 1.0917e-04, 6.2156e-06, 1.1149e-07, 7.9901e-08,\n",
            "         1.7198e-07, 1.5443e-07, 1.0000e+00],\n",
            "        [1.8244e-03, 3.4150e-07, 1.1495e-04, 6.6301e-06, 1.2118e-07, 8.6882e-08,\n",
            "         1.8599e-07, 1.6947e-07, 1.0000e+00],\n",
            "        [1.7241e-03, 3.0364e-07, 1.0612e-04, 6.0157e-06, 1.0649e-07, 7.6301e-08,\n",
            "         1.6472e-07, 1.4707e-07, 1.0000e+00],\n",
            "        [1.6616e-03, 2.8949e-07, 1.0272e-04, 5.7299e-06, 1.0097e-07, 7.2341e-08,\n",
            "         1.5661e-07, 1.3765e-07, 1.0000e+00],\n",
            "        [1.7902e-03, 3.2148e-07, 1.1031e-04, 6.3473e-06, 1.1342e-07, 8.1319e-08,\n",
            "         1.7495e-07, 1.5857e-07, 1.0000e+00],\n",
            "        [2.2312e-03, 4.4776e-07, 1.3744e-04, 8.7132e-06, 1.6251e-07, 1.1731e-07,\n",
            "         2.4694e-07, 2.4538e-07, 1.0000e+00]])\n",
            "targets shape == torch.Size([1])\n",
            "outputs shape== torch.Size([20, 9])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-7243b6510cf4>\u001b[0m in \u001b[0;36m<cell line: 116>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlogs_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs_f1_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m \u001b[0mlogs_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs_f1_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-31-7243b6510cf4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loss_fn, optimizer, train_data, dev_data, train_label, dev_label, epochs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0mdev_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                 \u001b[0mdev_targets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0maverage_dev_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdev_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: iteration over a 0-d array"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Task 1.4: Visualizing (5p)**\n",
        "\n",
        "Check the performance of the model on the test set and plot the training loss using `matplotlib.pyplot.plot`."
      ],
      "metadata": {
        "id": "xz6uyUXFWnAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate with test set\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    targets = []\n",
        "    # TODO: YOUR CODE HERE\n",
        "\n",
        "# Plot with matplotlib\n"
      ],
      "metadata": {
        "id": "enRLWn887ytw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}